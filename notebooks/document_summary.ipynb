{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import spacy_transformers\n",
    "from transformers import pipeline\n",
    "from dataclasses import dataclass\n",
    "from typing import Tuple\n",
    "from dataclasses import dataclass\n",
    "\n",
    "# !python -m spacy download en_core_web_trf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifier = pipeline(\"sentiment-analysis\", model=\"ProsusAI/finbert\")\n",
    "# nlp_spacy_trf = spacy.load(\"en_core_web_trf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class ExtractSummary:\n",
    "    \"\"\"Extract summary for a given paragraph.\n",
    "    \"\"\"\n",
    "    paragraph_meta: list\n",
    "    nlp_lang_model: spacy.lang\n",
    "    sentiment_model: pipeline\n",
    "    question_answer: bool = False\n",
    "    management_outlook: bool = False\n",
    "    \n",
    "    def __post_init__(self):\n",
    "        if self.question_answer:\n",
    "            # Creating a question corpus\n",
    "            question_corpus = self.create_corpus(\n",
    "                list(filter(lambda group: group[\"type\"] == \"question\", self.paragraph_meta))\n",
    "            )\n",
    "            # Extracting keywords from Questions\n",
    "            self.keywords = self.extract_keywords(\n",
    "                question_corpus\n",
    "            )\n",
    "            print(self.keywords)\n",
    "            # Creating an answer corpus\n",
    "            answer_corpus = self.create_corpus(\n",
    "                list(filter(lambda group: group[\"type\"] == \"answer\", self.paragraph_meta))\n",
    "            )\n",
    "            \n",
    "            \n",
    "            # Extracting summary from answers\n",
    "            \n",
    "#             self.summary = self.summarise_paragraph(\n",
    "#                 answer_corpus\n",
    "#             )\n",
    "        else:  # Management Outlook is provided\n",
    "#             self.outlook_paragraph = \n",
    "            pass\n",
    "    \n",
    "    def create_corpus(self, para_list: list) -> list:\n",
    "        \"\"\"Create an appended corpus.\"\"\"\n",
    "        corpus_doc = []\n",
    "        for each_doc in para_list:\n",
    "            corpus_doc.append(each_doc.get(\"paragraph\"))\n",
    "        \n",
    "        corpus = \"\".join(corpus_doc).split(\".\")\n",
    "        corpus = [text.strip() for text in corpus]\n",
    "        \n",
    "        return corpus\n",
    "        \n",
    "    def extract_keywords(self, para_list: list):\n",
    "        \"\"\"Extract Noun chunks from the question.\"\"\"\n",
    "        important_keywords = []\n",
    "#         nlp_doc = self.nlp_lang_model(para_list)\n",
    "        for doc in para_list:\n",
    "            for token in self.nlp_lang_model(doc):\n",
    "#                 print(token)\n",
    "                if (token.pos_ == \"NOUN\") and (not token.is_stop):\n",
    "                    important_keywords.append(token.text)\n",
    "\n",
    "        important_keywords = list(set(important_keywords))\n",
    "        keyword_string = \"\\n\".join(important_keywords)\n",
    "        \n",
    "        return keyword_string\n",
    "    \n",
    "    def summarise_paragraph(self, corpus: list):\n",
    "        \"\"\"\n",
    "        Get the sentiment of individual sentences and \n",
    "        create a summary basis set rules.\n",
    "        \"\"\"\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class SentimentExtractor:\n",
    "    corpus_list: list\n",
    "    sentiment_model: pipeline\n",
    "    \n",
    "    def create_sentiment_matrix(self):\n",
    "        sentiment_matrix = pd.DataFrame(None, columns=['Label', 'Score'])\n",
    "        sentiment_analysis_results = self.sentiment_model(self.corpus_list)\n",
    "\n",
    "        for idx, per_sentence_sentiment in enumerate(sentiment_analysis_results):\n",
    "            sentiment_matrix.loc[idx, ['Label', 'Score']] = (per_sentence_sentiment['label'], per_sentence_sentiment['score'])\n",
    "    \n",
    "    return sentiment_matrix\n",
    "\n",
    "    def extract_relevant_sentiment(sentiment_frame):\n",
    "        sentiment_frame[\"Relevance\"] = None\n",
    "        sentiment_frame.loc[sentiment_frame[\"Score\"] >= 0.8, \"Relevance\"]:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit ('con_summary_env': venv)",
   "language": "python",
   "name": "python391jvsc74a57bd012466f790b01845891e8c54f2878097070b87efd364ef8a7c7054cc189b73841"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
