{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import spacy_transformers\n",
    "from transformers import pipeline\n",
    "from dataclasses import dataclass\n",
    "from typing import Tuple\n",
    "\n",
    "# !python -m spacy download en_core_web_trf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = pipeline(\"sentiment-analysis\", model=\"ProsusAI/finbert\")\n",
    "nlp_spacy_trf = spacy.load(\"en_core_web_trf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class ExtractSummary:\n",
    "    \"\"\"Extract summary for a given paragraph.\n",
    "    \"\"\"\n",
    "    question_answer: bool\n",
    "    management_outlook: bool\n",
    "    paragraph_meta: list\n",
    "    nlp_lang_model: spacy.lang.en.English\n",
    "    \n",
    "    def __post_init__(self):\n",
    "        if self.question_answer:\n",
    "            # Creating a question corpus\n",
    "            answer_corpus = self.create_corpus(\n",
    "                list(filter(lambda group: group[\"type\"] == \"question\", self.paragraph_meta))\n",
    "            )\n",
    "            # Creating an answer corpus\n",
    "            answer_corpus = self.create_corpus(\n",
    "                list(filter(lambda group: group[\"type\"] == \"answer\", self.paragraph_meta))\n",
    "            )\n",
    "            # Extracting keywords from Questions\n",
    "            self.keywords = self.extract_keywords(\n",
    "                list(filter(lambda group: group[\"type\"] == \"question\", self.paragraph_meta))\n",
    "            )\n",
    "            \n",
    "            # Extracting summary from answers\n",
    "            \n",
    "            self.summary = self.summarise_paragraph(\n",
    "                \n",
    "            )\n",
    "        else:  # Management Outlook is provided\n",
    "            self.outlook_paragraph = \n",
    "        \n",
    "    \n",
    "    def create_corpus(self, para_list: list) -> list:\n",
    "        \"\"\"Create an appended corpus.\"\"\"\n",
    "        corpus_doc = []\n",
    "        for each_doc in para_list:\n",
    "            corpus_doc.append(each_doc.get(\"paragraph\"))\n",
    "        \n",
    "        corpus = \"\".join(corpus_doc).split\n",
    "        return\n",
    "        \n",
    "    def extract_keywords(self, para_list):\n",
    "        \"\"\"Extract Noun chunks from the question.\"\"\"\n",
    "        important_keywords = []\n",
    "        for each_doc in para_list:\n",
    "            for each_token in self.nlp_lang_model(each_doc.get(\"paragraph\")):\n",
    "                if each_token.pos_ == \"NOUN\":\n",
    "                    important_keywords.append(each_token.text)\n",
    "        \n",
    "        keyword_string = \", \".join(important_keywords)\n",
    "        \n",
    "        return keyword_string\n",
    "    \n",
    "    def summarise_paragraph(self):\n",
    "        pass\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit ('con_summary_env': venv)",
   "language": "python",
   "name": "python391jvsc74a57bd012466f790b01845891e8c54f2878097070b87efd364ef8a7c7054cc189b73841"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
