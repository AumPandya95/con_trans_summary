{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "u4G1frZz3b4x"
   },
   "outputs": [],
   "source": [
    "!pip install -q transformers\n",
    "!pip install -q sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "-tlUF60BFYF4"
   },
   "outputs": [],
   "source": [
    "# Transformer libraries\n",
    "from transformers import pipeline # For sentiment analysis\n",
    "from sentence_transformers import SentenceTransformer # For estimating the distance between (sub)sequences\n",
    "from sentence_transformers import util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "TsQ60aGHwmW9"
   },
   "outputs": [],
   "source": [
    "# Other libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer # For extracting n-grams from a sentence\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XgMz6soO3trH"
   },
   "source": [
    "**Section 1**\n",
    "\n",
    "Sentiment Analysis using FinBERT \n",
    "\n",
    "FinBERT is fine-tuned on financial textsets and returns three output classes - positive, neutral, and negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "geoxedAg3iw6"
   },
   "outputs": [],
   "source": [
    "classifier = pipeline('sentiment-analysis', model='ProsusAI/finbert')\n",
    "\n",
    "# # 3 classes - positive, neutral, and negative. However, the output corresponds to the class with the highest probability\n",
    "# classifier(['Biden comes to Europe with a goodwill gesture, a planned announcement that the United States will donate 500 million dollars to Pfizer Inc/BioNTech (PFE.N)',\n",
    "#             'US will provide coronavirus vaccine doses to about 100 countries over the next two years, three sources familiar with the matter told Reuters',\n",
    "#             'The Canadian minister for trade stated that the business sentiment was down 30% in Canada'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 232
    },
    "id": "vmcZ8MI6CfWc",
    "outputId": "cf3d18a4-a37b-4cd3-9bf8-b0d39c53c343"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  cpuset_checked))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>positive</td>\n",
       "      <td>0.700791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neutral</td>\n",
       "      <td>0.818340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>negative</td>\n",
       "      <td>0.974742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>neutral</td>\n",
       "      <td>0.884604</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Label     Score\n",
       "0  positive  0.700791\n",
       "1   neutral  0.818340\n",
       "2  negative  0.974742\n",
       "3   neutral  0.884604"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_list = ['Biden comes to Europe with a goodwill gesture, a planned announcement that the United States will donate 500 million dollars to Pfizer Inc/BioNTech (PFE.N)',\n",
    "            'US will provide coronavirus vaccine doses to about 100 countries over the next two years, three sources familiar with the matter told Reuters',\n",
    "            'The Canadian minister for trade stated that the business sentiment was down 30% in Canada',\n",
    "            'For your second question we would launch around F4 to F5 products next year and in the FY24 we would have similar plans']\n",
    "\n",
    "num_sentences = len(input_list)\n",
    "out_matrix = pd.DataFrame(0, index=np.arange(num_sentences), columns=['Label', 'Score'])\n",
    "\n",
    "out_list = classifier(input_list)\n",
    "for idx, per_sentence_sentiment in enumerate(out_list):\n",
    "  out_matrix.iloc[idx, 0:] = (per_sentence_sentiment['label'], per_sentence_sentiment['score'])\n",
    "\n",
    "out_matrix  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3mEEtaGyCA3e"
   },
   "source": [
    "**Section 2**\n",
    "\n",
    "Identify the subsequence that has the highest semantic similarity to the original sequence\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "mLfarEjtLfwl"
   },
   "outputs": [],
   "source": [
    "# Load the spaCy model for POS tags\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "p8bpGpzkEBYx"
   },
   "outputs": [],
   "source": [
    "# Instantiate SBERT\n",
    "sentence_model = SentenceTransformer('all-mpnet-base-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "OcY75tC9SInV"
   },
   "outputs": [],
   "source": [
    "orig_corpus = ['For your second question we would launch around 4 to 5 products next year and in the FY24 we would have similar plans']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IqWo8lsmnHDK"
   },
   "source": [
    "Section 2.1 -- Convert numbers to strings so that they are not removed during the generation of n-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 771
    },
    "id": "yVnCrZ_ER4JE",
    "outputId": "d24585e6-6b48-4bd9-df80-69aea88e7b5a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>POS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>For</td>\n",
       "      <td>ADP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>your</td>\n",
       "      <td>DET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>second</td>\n",
       "      <td>ADJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>question</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>we</td>\n",
       "      <td>PRON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>would</td>\n",
       "      <td>VERB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>launch</td>\n",
       "      <td>VERB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>around</td>\n",
       "      <td>ADV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4</td>\n",
       "      <td>NUM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>to</td>\n",
       "      <td>PART</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5</td>\n",
       "      <td>NUM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>products</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>next</td>\n",
       "      <td>ADP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>year</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>and</td>\n",
       "      <td>CCONJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>in</td>\n",
       "      <td>ADP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>the</td>\n",
       "      <td>DET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>FY24</td>\n",
       "      <td>PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>we</td>\n",
       "      <td>PRON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>would</td>\n",
       "      <td>VERB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>have</td>\n",
       "      <td>AUX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>similar</td>\n",
       "      <td>ADJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>plans</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Text    POS\n",
       "0        For    ADP\n",
       "1       your    DET\n",
       "2     second    ADJ\n",
       "3   question   NOUN\n",
       "4         we   PRON\n",
       "5      would   VERB\n",
       "6     launch   VERB\n",
       "7     around    ADV\n",
       "8          4    NUM\n",
       "9         to   PART\n",
       "10         5    NUM\n",
       "11  products   NOUN\n",
       "12      next    ADP\n",
       "13      year   NOUN\n",
       "14       and  CCONJ\n",
       "15        in    ADP\n",
       "16       the    DET\n",
       "17      FY24  PROPN\n",
       "18        we   PRON\n",
       "19     would   VERB\n",
       "20      have    AUX\n",
       "21   similar    ADJ\n",
       "22     plans   NOUN"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Infer numbers using POS tags for conversion to character strings\n",
    "corpus_tokens = nlp(orig_corpus[0])\n",
    "col_names = ['Text', 'POS']\n",
    "output_df = pd.DataFrame([], columns = col_names)\n",
    "\n",
    "for token in corpus_tokens:\n",
    "    inlist = pd.DataFrame([[token.text, token.pos_]], columns=col_names)\n",
    "    output_df = pd.concat([output_df, inlist], ignore_index=True)\n",
    "\n",
    "output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "ooF8MmciTALZ",
    "outputId": "e510a9f0-1631-469b-ba17-5543cdefe397"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'For your second question we would launch around F4 to F5 products next year and in the FY24 we would have similar plans'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_idx = np.where(output_df['POS'] == 'NUM')[0]\n",
    "# num_idx\n",
    "\n",
    "output_df.iloc[num_idx, 0]  = 'F' + output_df.iloc[num_idx, 0]\n",
    "# output_df\n",
    "\n",
    "revised_corpus = output_df['Text'].str.cat(sep=' ')\n",
    "revised_corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cAl3o_whn8He"
   },
   "source": [
    "Section 2.2 -- Generate n-grams and estimate the similarity between the n-grams and the original sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H1DIZGblCOrg",
    "outputId": "903c493e-6d65-4ebf-9f11-17e9b6fe6e4e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate n-grams (tokens) of a predefined size from a single sentence\n",
    "# corpus = ['For your second question we would launch around 4 to 5 products next year and in the FY24 we would have similar plans']\n",
    "\n",
    "# Modify numbers in the sentence using the prefix \"F\"\n",
    "# corpus = ['For your second question we would launch around F4 to F5 products next year and in the FY24 we would have similar plans']\n",
    "corpus = [revised_corpus]\n",
    "vectorizer = CountVectorizer(ngram_range=(11,13))\n",
    "temp = vectorizer.fit_transform(corpus)\n",
    "sub_sequence_list = vectorizer.get_feature_names()\n",
    "\n",
    "# for list_element in sub_sequence_list:\n",
    "#   print(list_element)\n",
    "\n",
    "len(sub_sequence_list)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vWTN9vRZn1Go",
    "outputId": "58d331af-32bb-481e-a12b-4939dac45564"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['around f4 to f5 products next year and in the fy24',\n",
       " 'around f4 to f5 products next year and in the fy24 we',\n",
       " 'around f4 to f5 products next year and in the fy24 we would',\n",
       " 'f4 to f5 products next year and in the fy24 we',\n",
       " 'f4 to f5 products next year and in the fy24 we would',\n",
       " 'f4 to f5 products next year and in the fy24 we would have',\n",
       " 'f5 products next year and in the fy24 we would have',\n",
       " 'f5 products next year and in the fy24 we would have similar',\n",
       " 'f5 products next year and in the fy24 we would have similar plans',\n",
       " 'for your second question we would launch around f4 to f5',\n",
       " 'for your second question we would launch around f4 to f5 products',\n",
       " 'for your second question we would launch around f4 to f5 products next',\n",
       " 'launch around f4 to f5 products next year and in the',\n",
       " 'launch around f4 to f5 products next year and in the fy24',\n",
       " 'launch around f4 to f5 products next year and in the fy24 we',\n",
       " 'next year and in the fy24 we would have similar plans',\n",
       " 'products next year and in the fy24 we would have similar',\n",
       " 'products next year and in the fy24 we would have similar plans',\n",
       " 'question we would launch around f4 to f5 products next year',\n",
       " 'question we would launch around f4 to f5 products next year and',\n",
       " 'question we would launch around f4 to f5 products next year and in',\n",
       " 'second question we would launch around f4 to f5 products next',\n",
       " 'second question we would launch around f4 to f5 products next year',\n",
       " 'second question we would launch around f4 to f5 products next year and',\n",
       " 'to f5 products next year and in the fy24 we would',\n",
       " 'to f5 products next year and in the fy24 we would have',\n",
       " 'to f5 products next year and in the fy24 we would have similar',\n",
       " 'we would launch around f4 to f5 products next year and',\n",
       " 'we would launch around f4 to f5 products next year and in',\n",
       " 'we would launch around f4 to f5 products next year and in the',\n",
       " 'would launch around f4 to f5 products next year and in',\n",
       " 'would launch around f4 to f5 products next year and in the',\n",
       " 'would launch around f4 to f5 products next year and in the fy24',\n",
       " 'your second question we would launch around f4 to f5 products',\n",
       " 'your second question we would launch around f4 to f5 products next',\n",
       " 'your second question we would launch around f4 to f5 products next year']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_sequence_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "T4Q1V_V2D6ma"
   },
   "outputs": [],
   "source": [
    "# Calculate pairwise cosine similarity between elements in the query list and passage list\n",
    "# Out[i][j] corresponds to the cosine similarity between query_list[i] and passagelist[j]\n",
    "query_embedding = sentence_model.encode(corpus)\n",
    "passage_embedding = sentence_model.encode(sub_sequence_list)\n",
    "similarity_list =  util.cos_sim(query_embedding, passage_embedding).numpy()\n",
    "# similarity_list\n",
    "\n",
    "# Sort in ascending order and obtain the top 3 subsequences\n",
    "top_3_idx = np.argsort(similarity_list)[0, -3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "ZdfYgZSVG4h5",
    "outputId": "faae4691-a228-4f9e-e379-bcc72b42331d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence</th>\n",
       "      <th>cosine_similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>around f4 to f5 products next year and in the ...</td>\n",
       "      <td>0.779239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>around f4 to f5 products next year and in the ...</td>\n",
       "      <td>0.808505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>around f4 to f5 products next year and in the ...</td>\n",
       "      <td>0.827823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>f4 to f5 products next year and in the fy24 we</td>\n",
       "      <td>0.789200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>f4 to f5 products next year and in the fy24 we...</td>\n",
       "      <td>0.777601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>f4 to f5 products next year and in the fy24 we...</td>\n",
       "      <td>0.750035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>f5 products next year and in the fy24 we would...</td>\n",
       "      <td>0.726326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>f5 products next year and in the fy24 we would...</td>\n",
       "      <td>0.768127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>f5 products next year and in the fy24 we would...</td>\n",
       "      <td>0.851965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>for your second question we would launch aroun...</td>\n",
       "      <td>0.501838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>for your second question we would launch aroun...</td>\n",
       "      <td>0.847248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>for your second question we would launch aroun...</td>\n",
       "      <td>0.890803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>launch around f4 to f5 products next year and ...</td>\n",
       "      <td>0.811803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>launch around f4 to f5 products next year and ...</td>\n",
       "      <td>0.839995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>launch around f4 to f5 products next year and ...</td>\n",
       "      <td>0.855114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>next year and in the fy24 we would have simila...</td>\n",
       "      <td>0.629730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>products next year and in the fy24 we would ha...</td>\n",
       "      <td>0.766323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>products next year and in the fy24 we would ha...</td>\n",
       "      <td>0.843670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>question we would launch around f4 to f5 produ...</td>\n",
       "      <td>0.880684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>question we would launch around f4 to f5 produ...</td>\n",
       "      <td>0.889197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>question we would launch around f4 to f5 produ...</td>\n",
       "      <td>0.891530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>second question we would launch around f4 to f...</td>\n",
       "      <td>0.836455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>second question we would launch around f4 to f...</td>\n",
       "      <td>0.918208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>second question we would launch around f4 to f...</td>\n",
       "      <td>0.920358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>to f5 products next year and in the fy24 we would</td>\n",
       "      <td>0.772237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>to f5 products next year and in the fy24 we wo...</td>\n",
       "      <td>0.738631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>to f5 products next year and in the fy24 we wo...</td>\n",
       "      <td>0.774842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>we would launch around f4 to f5 products next ...</td>\n",
       "      <td>0.880877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>we would launch around f4 to f5 products next ...</td>\n",
       "      <td>0.877827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>we would launch around f4 to f5 products next ...</td>\n",
       "      <td>0.882530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>would launch around f4 to f5 products next yea...</td>\n",
       "      <td>0.850271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>would launch around f4 to f5 products next yea...</td>\n",
       "      <td>0.854085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>would launch around f4 to f5 products next yea...</td>\n",
       "      <td>0.881129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>your second question we would launch around f4...</td>\n",
       "      <td>0.848846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>your second question we would launch around f4...</td>\n",
       "      <td>0.878545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>your second question we would launch around f4...</td>\n",
       "      <td>0.946437</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             sequence  cosine_similarity\n",
       "0   around f4 to f5 products next year and in the ...           0.779239\n",
       "1   around f4 to f5 products next year and in the ...           0.808505\n",
       "2   around f4 to f5 products next year and in the ...           0.827823\n",
       "3      f4 to f5 products next year and in the fy24 we           0.789200\n",
       "4   f4 to f5 products next year and in the fy24 we...           0.777601\n",
       "5   f4 to f5 products next year and in the fy24 we...           0.750035\n",
       "6   f5 products next year and in the fy24 we would...           0.726326\n",
       "7   f5 products next year and in the fy24 we would...           0.768127\n",
       "8   f5 products next year and in the fy24 we would...           0.851965\n",
       "9   for your second question we would launch aroun...           0.501838\n",
       "10  for your second question we would launch aroun...           0.847248\n",
       "11  for your second question we would launch aroun...           0.890803\n",
       "12  launch around f4 to f5 products next year and ...           0.811803\n",
       "13  launch around f4 to f5 products next year and ...           0.839995\n",
       "14  launch around f4 to f5 products next year and ...           0.855114\n",
       "15  next year and in the fy24 we would have simila...           0.629730\n",
       "16  products next year and in the fy24 we would ha...           0.766323\n",
       "17  products next year and in the fy24 we would ha...           0.843670\n",
       "18  question we would launch around f4 to f5 produ...           0.880684\n",
       "19  question we would launch around f4 to f5 produ...           0.889197\n",
       "20  question we would launch around f4 to f5 produ...           0.891530\n",
       "21  second question we would launch around f4 to f...           0.836455\n",
       "22  second question we would launch around f4 to f...           0.918208\n",
       "23  second question we would launch around f4 to f...           0.920358\n",
       "24  to f5 products next year and in the fy24 we would           0.772237\n",
       "25  to f5 products next year and in the fy24 we wo...           0.738631\n",
       "26  to f5 products next year and in the fy24 we wo...           0.774842\n",
       "27  we would launch around f4 to f5 products next ...           0.880877\n",
       "28  we would launch around f4 to f5 products next ...           0.877827\n",
       "29  we would launch around f4 to f5 products next ...           0.882530\n",
       "30  would launch around f4 to f5 products next yea...           0.850271\n",
       "31  would launch around f4 to f5 products next yea...           0.854085\n",
       "32  would launch around f4 to f5 products next yea...           0.881129\n",
       "33  your second question we would launch around f4...           0.848846\n",
       "34  your second question we would launch around f4...           0.878545\n",
       "35  your second question we would launch around f4...           0.946437"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp_array = pd.DataFrame({'sequence':sub_sequence_list, 'cosine_similarity':similarity_list[0, :]})\n",
    "imp_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 476
    },
    "id": "ijDQT3OzHZyi",
    "outputId": "eab735fa-d00c-4e72-b5da-9f1033b89438"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "your second question we would launch around f4 to f5 products next year\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>POS</th>\n",
       "      <th>STOPWORD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>your</td>\n",
       "      <td>DET</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>second</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>question</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>we</td>\n",
       "      <td>PRON</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>would</td>\n",
       "      <td>VERB</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>launch</td>\n",
       "      <td>VERB</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>around</td>\n",
       "      <td>ADP</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>f4</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>to</td>\n",
       "      <td>ADP</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>f5</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>products</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>next</td>\n",
       "      <td>ADP</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>year</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Text    POS STOPWORD\n",
       "0       your    DET     True\n",
       "1     second    ADJ    False\n",
       "2   question   NOUN    False\n",
       "3         we   PRON     True\n",
       "4      would   VERB     True\n",
       "5     launch   VERB    False\n",
       "6     around    ADP     True\n",
       "7         f4  PROPN    False\n",
       "8         to    ADP     True\n",
       "9         f5  PROPN    False\n",
       "10  products   NOUN    False\n",
       "11      next    ADP     True\n",
       "12      year   NOUN    False"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use POS tag to determine the start of the best subsequence\n",
    "best_sentence = imp_array.iloc[top_3_idx[2],0]\n",
    "print(best_sentence)\n",
    "\n",
    "# Obtain POS per token\n",
    "best_sent_tokens = nlp(best_sentence)\n",
    "col_names = ['Text', 'POS', 'STOPWORD']\n",
    "output_df = pd.DataFrame([], columns = col_names)\n",
    "\n",
    "for token in best_sent_tokens:\n",
    "    inlist = pd.DataFrame([[token.text, token.pos_, token.is_stop]], columns=col_names)\n",
    "    output_df = pd.concat([output_df, inlist], ignore_index=True)\n",
    "    \n",
    "output_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "64zOm6ybqrZP"
   },
   "source": [
    "Section 2.3 -- Potentially use the locations of \"verbs\" and \"stopwords\" to generate bullet points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "fH8h3y17qo09",
    "outputId": "846f0135-99ce-4cc0-f39b-c49524b55cae"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'launch around f4 to f5 products next year'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "verb_pos = np.where(output_df['POS'] == 'VERB')[0]\n",
    "stop_pos = np.where(output_df['STOPWORD'] == True)[0]\n",
    "first_verb = list(set(verb_pos) - set(stop_pos))\n",
    "output_df.iloc[first_verb[0]:, 0].str.cat(sep=' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T3n_UDN1jbfn"
   },
   "source": [
    "**Section 3**\n",
    "\n",
    "Use Maximal Marginal Relevance (MMR) metric to identify the most distinct subsequences from the same sequence/sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "CZupxupfjbPb"
   },
   "outputs": [],
   "source": [
    "def mmr(in_sequence_list, in_best_sequence, in_query, in_alpha, in_count_elements):\n",
    "  num_elements = min(in_count_elements, len(in_sequence_list))\n",
    "\n",
    "  # Ensure that the original lists are not modified\n",
    "  rem_sequence_list = in_sequence_list.copy()\n",
    "  current_list = in_best_sequence.copy()\n",
    "\n",
    "  query_embedding = sentence_model.encode(in_query)\n",
    "\n",
    "  # Add new elements to 'current_list'\n",
    "  for idx in range(num_elements):\n",
    "    print(idx)\n",
    "    passage_embedding = sentence_model.encode(rem_sequence_list)\n",
    "    current_list_embedding = sentence_model.encode(current_list)\n",
    "\n",
    "    # sim(D_i, Q)\n",
    "    seq_to_query_sim = util.cos_sim(query_embedding, passage_embedding).numpy()\n",
    "\n",
    "    # sim(D_i, D_j)\n",
    "    seq_to_seq_sim = util.cos_sim(passage_embedding, current_list_embedding).numpy()\n",
    "    seq_to_seq_max = np.amax(seq_to_seq_sim, axis=1) # Obtain the maximum per row or max[sim(D_i, D_j)]\n",
    "\n",
    "    # Identify the sequence with MMR\n",
    "    per_seq_val = in_alpha*seq_to_query_sim[0, :] - (1-in_alpha)*seq_to_seq_max\n",
    "    max_idx = np.argmax(per_seq_val)\n",
    "\n",
    "    # Add the best sequence to the current_list\n",
    "    current_list = current_list + [rem_sequence_list[max_idx]]\n",
    "    rem_sequence_list.pop(max_idx)\n",
    "\n",
    "  return current_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aqszP-zt5Pox"
   },
   "source": [
    "Section 3.1 -- Test MMR function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Zf6LQPaVsVJ5",
    "outputId": "985c241e-e369-4be9-e69a-bc8bed0743b7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the sequences into the best sequence and the remaining sequences\n",
    "best_sequence = [sub_sequence_list[top_3_idx[2]]]\n",
    "\n",
    "sequence_list = sub_sequence_list.copy()\n",
    "sequence_list.pop(top_3_idx[2])\n",
    "len(sequence_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PhvT9aeSxOOk"
   },
   "source": [
    "(1) If alpha=1, then subsequences with the highest match to the original query will be selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KPDi2EVIvNgM",
    "outputId": "5dae6df6-d2b4-467d-f86b-9e55af487dd6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['your second question we would launch around f4 to f5 products next year',\n",
       " 'second question we would launch around f4 to f5 products next year and',\n",
       " 'second question we would launch around f4 to f5 products next year',\n",
       " 'question we would launch around f4 to f5 products next year and in']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mmr(sequence_list, best_sequence, revised_corpus, 1, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9jVAG0CNvbBX",
    "outputId": "a1650864-27d8-4724-9965-a999bb26413e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "your second question we would launch around f4 to f5 products next year\n",
      "second question we would launch around f4 to f5 products next year and\n",
      "second question we would launch around f4 to f5 products next year\n",
      "question we would launch around f4 to f5 products next year and in\n"
     ]
    }
   ],
   "source": [
    "zz = imp_array.sort_values(by=['cosine_similarity'], ascending=False, ignore_index=True)\n",
    "for idx in range(4):\n",
    "  print(zz['sequence'][idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zl9XjOWLxlep"
   },
   "source": [
    "(2) If alpha=0, then subsequences with the lowest match to the existing subsequences will be selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "VyOxXgrQx2P-"
   },
   "outputs": [],
   "source": [
    "temp_1 = sentence_model.encode(best_sequence)\n",
    "temp_2 = sentence_model.encode(sequence_list)\n",
    "temp_3 = util.cos_sim(temp_1, temp_2).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I_gyeqizzDvJ",
    "outputId": "20fa9e2c-2d67-457c-e0e3-4ec7472edf90"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(-temp_3[0, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "TIqOqLaLzRvv",
    "outputId": "fbab34ec-8338-4be5-81c0-6c70f8dfbb59"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'next year and in the fy24 we would have similar plans'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence_list[15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CVTnKjDZptMP",
    "outputId": "5c396fb3-c11a-4162-8e20-20f1f36f447a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['your second question we would launch around f4 to f5 products next year',\n",
       " 'next year and in the fy24 we would have similar plans',\n",
       " 'for your second question we would launch around f4 to f5',\n",
       " 'products next year and in the fy24 we would have similar']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mmr(sequence_list, best_sequence, revised_corpus, 0, 3)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Code_Snippets_NLU.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "concall_summary",
   "language": "python",
   "name": "con_summary_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
