{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "u4G1frZz3b4x",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /home/aumaron/Desktop/nlp/con_trans_summary/con_summary_env/lib/python3.9/site-packages (4.11.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/aumaron/Desktop/nlp/con_trans_summary/con_summary_env/lib/python3.9/site-packages (from transformers) (1.21.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/aumaron/Desktop/nlp/con_trans_summary/con_summary_env/lib/python3.9/site-packages (from transformers) (4.62.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/aumaron/Desktop/nlp/con_trans_summary/con_summary_env/lib/python3.9/site-packages (from transformers) (21.0)\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /home/aumaron/Desktop/nlp/con_trans_summary/con_summary_env/lib/python3.9/site-packages (from transformers) (0.10.3)\n",
      "Requirement already satisfied: huggingface-hub>=0.0.17 in /home/aumaron/Desktop/nlp/con_trans_summary/con_summary_env/lib/python3.9/site-packages (from transformers) (0.0.19)\n",
      "Requirement already satisfied: sacremoses in /home/aumaron/Desktop/nlp/con_trans_summary/con_summary_env/lib/python3.9/site-packages (from transformers) (0.0.46)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/aumaron/Desktop/nlp/con_trans_summary/con_summary_env/lib/python3.9/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: filelock in /home/aumaron/Desktop/nlp/con_trans_summary/con_summary_env/lib/python3.9/site-packages (from transformers) (3.3.1)\n",
      "Requirement already satisfied: requests in /home/aumaron/Desktop/nlp/con_trans_summary/con_summary_env/lib/python3.9/site-packages (from transformers) (2.26.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/aumaron/Desktop/nlp/con_trans_summary/con_summary_env/lib/python3.9/site-packages (from transformers) (2021.10.23)\n",
      "Requirement already satisfied: typing-extensions in /home/aumaron/Desktop/nlp/con_trans_summary/con_summary_env/lib/python3.9/site-packages (from huggingface-hub>=0.0.17->transformers) (3.10.0.2)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /home/aumaron/Desktop/nlp/con_trans_summary/con_summary_env/lib/python3.9/site-packages (from packaging>=20.0->transformers) (3.0.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/aumaron/Desktop/nlp/con_trans_summary/con_summary_env/lib/python3.9/site-packages (from requests->transformers) (1.26.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/aumaron/Desktop/nlp/con_trans_summary/con_summary_env/lib/python3.9/site-packages (from requests->transformers) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/aumaron/Desktop/nlp/con_trans_summary/con_summary_env/lib/python3.9/site-packages (from requests->transformers) (2.0.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/aumaron/Desktop/nlp/con_trans_summary/con_summary_env/lib/python3.9/site-packages (from requests->transformers) (3.3)\n",
      "Requirement already satisfied: joblib in /home/aumaron/Desktop/nlp/con_trans_summary/con_summary_env/lib/python3.9/site-packages (from sacremoses->transformers) (1.1.0)\n",
      "Requirement already satisfied: click in /home/aumaron/Desktop/nlp/con_trans_summary/con_summary_env/lib/python3.9/site-packages (from sacremoses->transformers) (8.0.3)\n",
      "Requirement already satisfied: six in /home/aumaron/Desktop/nlp/con_trans_summary/con_summary_env/lib/python3.9/site-packages (from sacremoses->transformers) (1.16.0)\n",
      "Requirement already satisfied: sentence-transformers in /home/aumaron/Desktop/nlp/con_trans_summary/con_summary_env/lib/python3.9/site-packages (2.1.0)\n",
      "Requirement already satisfied: tqdm in /home/aumaron/Desktop/nlp/con_trans_summary/con_summary_env/lib/python3.9/site-packages (from sentence-transformers) (4.62.3)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /home/aumaron/Desktop/nlp/con_trans_summary/con_summary_env/lib/python3.9/site-packages (from sentence-transformers) (4.11.3)\n",
      "Requirement already satisfied: nltk in /home/aumaron/Desktop/nlp/con_trans_summary/con_summary_env/lib/python3.9/site-packages (from sentence-transformers) (3.6.5)\n",
      "Requirement already satisfied: tokenizers>=0.10.3 in /home/aumaron/Desktop/nlp/con_trans_summary/con_summary_env/lib/python3.9/site-packages (from sentence-transformers) (0.10.3)\n",
      "Requirement already satisfied: torchvision in /home/aumaron/Desktop/nlp/con_trans_summary/con_summary_env/lib/python3.9/site-packages (from sentence-transformers) (0.11.1)\n",
      "Requirement already satisfied: numpy in /home/aumaron/Desktop/nlp/con_trans_summary/con_summary_env/lib/python3.9/site-packages (from sentence-transformers) (1.21.3)\n",
      "Requirement already satisfied: huggingface-hub in /home/aumaron/Desktop/nlp/con_trans_summary/con_summary_env/lib/python3.9/site-packages (from sentence-transformers) (0.0.19)\n",
      "Requirement already satisfied: sentencepiece in /home/aumaron/Desktop/nlp/con_trans_summary/con_summary_env/lib/python3.9/site-packages (from sentence-transformers) (0.1.96)\n",
      "Requirement already satisfied: torch>=1.6.0 in /home/aumaron/Desktop/nlp/con_trans_summary/con_summary_env/lib/python3.9/site-packages (from sentence-transformers) (1.10.0)\n",
      "Requirement already satisfied: scipy in /home/aumaron/Desktop/nlp/con_trans_summary/con_summary_env/lib/python3.9/site-packages (from sentence-transformers) (1.7.1)\n",
      "Requirement already satisfied: scikit-learn in /home/aumaron/Desktop/nlp/con_trans_summary/con_summary_env/lib/python3.9/site-packages (from sentence-transformers) (1.0.1)\n",
      "Requirement already satisfied: typing-extensions in /home/aumaron/Desktop/nlp/con_trans_summary/con_summary_env/lib/python3.9/site-packages (from torch>=1.6.0->sentence-transformers) (3.10.0.2)\n",
      "Requirement already satisfied: sacremoses in /home/aumaron/Desktop/nlp/con_trans_summary/con_summary_env/lib/python3.9/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.0.46)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/aumaron/Desktop/nlp/con_trans_summary/con_summary_env/lib/python3.9/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2021.10.23)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/aumaron/Desktop/nlp/con_trans_summary/con_summary_env/lib/python3.9/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (6.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/aumaron/Desktop/nlp/con_trans_summary/con_summary_env/lib/python3.9/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (21.0)\n",
      "Requirement already satisfied: requests in /home/aumaron/Desktop/nlp/con_trans_summary/con_summary_env/lib/python3.9/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2.26.0)\n",
      "Requirement already satisfied: filelock in /home/aumaron/Desktop/nlp/con_trans_summary/con_summary_env/lib/python3.9/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (3.3.1)\n",
      "Requirement already satisfied: click in /home/aumaron/Desktop/nlp/con_trans_summary/con_summary_env/lib/python3.9/site-packages (from nltk->sentence-transformers) (8.0.3)\n",
      "Requirement already satisfied: joblib in /home/aumaron/Desktop/nlp/con_trans_summary/con_summary_env/lib/python3.9/site-packages (from nltk->sentence-transformers) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/aumaron/Desktop/nlp/con_trans_summary/con_summary_env/lib/python3.9/site-packages (from scikit-learn->sentence-transformers) (3.0.0)\n",
      "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /home/aumaron/Desktop/nlp/con_trans_summary/con_summary_env/lib/python3.9/site-packages (from torchvision->sentence-transformers) (8.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /home/aumaron/Desktop/nlp/con_trans_summary/con_summary_env/lib/python3.9/site-packages (from packaging>=20.0->transformers<5.0.0,>=4.6.0->sentence-transformers) (3.0.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/aumaron/Desktop/nlp/con_trans_summary/con_summary_env/lib/python3.9/site-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (1.26.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/aumaron/Desktop/nlp/con_trans_summary/con_summary_env/lib/python3.9/site-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/aumaron/Desktop/nlp/con_trans_summary/con_summary_env/lib/python3.9/site-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/aumaron/Desktop/nlp/con_trans_summary/con_summary_env/lib/python3.9/site-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (2021.10.8)\n",
      "Requirement already satisfied: six in /home/aumaron/Desktop/nlp/con_trans_summary/con_summary_env/lib/python3.9/site-packages (from sacremoses->transformers<5.0.0,>=4.6.0->sentence-transformers) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n",
    "!pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting spacy\n",
      "  Downloading spacy-3.1.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.9 MB)\n",
      "     |████████████████████████████████| 5.9 MB 2.9 MB/s            \n",
      "\u001b[?25hCollecting jinja2\n",
      "  Using cached Jinja2-3.0.2-py3-none-any.whl (133 kB)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0\n",
      "  Using cached murmurhash-1.0.6-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (21 kB)\n",
      "Collecting srsly<3.0.0,>=2.4.1\n",
      "  Downloading srsly-2.4.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (452 kB)\n",
      "     |████████████████████████████████| 452 kB 3.2 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: requests<3.0.0,>=2.13.0 in /home/aumaron/Desktop/nlp/con_trans_summary/con_summary_env/lib/python3.9/site-packages (from spacy) (2.26.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/aumaron/Desktop/nlp/con_trans_summary/con_summary_env/lib/python3.9/site-packages (from spacy) (21.0)\n",
      "Collecting thinc<8.1.0,>=8.0.9\n",
      "  Downloading thinc-8.0.11-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (635 kB)\n",
      "     |████████████████████████████████| 635 kB 4.5 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.15.0 in /home/aumaron/Desktop/nlp/con_trans_summary/con_summary_env/lib/python3.9/site-packages (from spacy) (1.21.3)\n",
      "Collecting pathy>=0.3.5\n",
      "  Downloading pathy-0.6.1-py3-none-any.whl (42 kB)\n",
      "     |████████████████████████████████| 42 kB 1.7 MB/s            \n",
      "\u001b[?25hCollecting wasabi<1.1.0,>=0.8.1\n",
      "  Using cached wasabi-0.8.2-py3-none-any.whl (23 kB)\n",
      "Collecting preshed<3.1.0,>=3.0.2\n",
      "  Downloading preshed-3.0.6-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (128 kB)\n",
      "     |████████████████████████████████| 128 kB 4.6 MB/s            \n",
      "\u001b[?25hCollecting spacy-legacy<3.1.0,>=3.0.8\n",
      "  Using cached spacy_legacy-3.0.8-py2.py3-none-any.whl (14 kB)\n",
      "Collecting catalogue<2.1.0,>=2.0.6\n",
      "  Using cached catalogue-2.0.6-py3-none-any.whl (17 kB)\n",
      "Collecting pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4\n",
      "  Using cached pydantic-1.8.2-cp39-cp39-manylinux2014_x86_64.whl (11.3 MB)\n",
      "Collecting typer<0.5.0,>=0.3.0\n",
      "  Downloading typer-0.4.0-py3-none-any.whl (27 kB)\n",
      "Requirement already satisfied: setuptools in /home/aumaron/Desktop/nlp/con_trans_summary/con_summary_env/lib/python3.9/site-packages (from spacy) (58.3.0)\n",
      "Collecting cymem<2.1.0,>=2.0.2\n",
      "  Using cached cymem-2.0.6-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (35 kB)\n",
      "Collecting blis<0.8.0,>=0.4.0\n",
      "  Using cached blis-0.7.5-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.9 MB)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /home/aumaron/Desktop/nlp/con_trans_summary/con_summary_env/lib/python3.9/site-packages (from spacy) (4.62.3)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /home/aumaron/Desktop/nlp/con_trans_summary/con_summary_env/lib/python3.9/site-packages (from packaging>=20.0->spacy) (3.0.1)\n",
      "Collecting smart-open<6.0.0,>=5.0.0\n",
      "  Downloading smart_open-5.2.1-py3-none-any.whl (58 kB)\n",
      "     |████████████████████████████████| 58 kB 4.5 MB/s             \n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /home/aumaron/Desktop/nlp/con_trans_summary/con_summary_env/lib/python3.9/site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy) (3.10.0.2)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/aumaron/Desktop/nlp/con_trans_summary/con_summary_env/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/aumaron/Desktop/nlp/con_trans_summary/con_summary_env/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/aumaron/Desktop/nlp/con_trans_summary/con_summary_env/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/aumaron/Desktop/nlp/con_trans_summary/con_summary_env/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /home/aumaron/Desktop/nlp/con_trans_summary/con_summary_env/lib/python3.9/site-packages (from typer<0.5.0,>=0.3.0->spacy) (8.0.3)\n",
      "Collecting MarkupSafe>=2.0\n",
      "  Using cached MarkupSafe-2.0.1-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (30 kB)\n",
      "Installing collected packages: murmurhash, cymem, catalogue, wasabi, typer, srsly, smart-open, pydantic, preshed, MarkupSafe, blis, thinc, spacy-legacy, pathy, jinja2, spacy\n",
      "Successfully installed MarkupSafe-2.0.1 blis-0.7.5 catalogue-2.0.6 cymem-2.0.6 jinja2-3.0.2 murmurhash-1.0.6 pathy-0.6.1 preshed-3.0.6 pydantic-1.8.2 smart-open-5.2.1 spacy-3.1.3 spacy-legacy-3.0.8 srsly-2.4.2 thinc-8.0.11 typer-0.4.0 wasabi-0.8.2\n"
     ]
    }
   ],
   "source": [
    "!pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "-tlUF60BFYF4"
   },
   "outputs": [],
   "source": [
    "# Transformer libraries\n",
    "from transformers import pipeline # For sentiment analysis\n",
    "from sentence_transformers import SentenceTransformer # For estimating the distance between (sub)sequences\n",
    "from sentence_transformers import util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "TsQ60aGHwmW9"
   },
   "outputs": [],
   "source": [
    "# Other libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer # For extracting n-grams from a sentence\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XgMz6soO3trH"
   },
   "source": [
    "**Section 1**\n",
    "\n",
    "Sentiment Analysis using FinBERT \n",
    "\n",
    "FinBERT is fine-tuned on financial textsets and returns three output classes - positive, neutral, and negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "geoxedAg3iw6"
   },
   "outputs": [],
   "source": [
    "classifier = pipeline('sentiment-analysis', model='ProsusAI/finbert')\n",
    "\n",
    "# # 3 classes - positive, neutral, and negative. However, the output corresponds to the class with the highest probability\n",
    "# classifier(['Biden comes to Europe with a goodwill gesture, a planned announcement that the United States will donate 500 million dollars to Pfizer Inc/BioNTech (PFE.N)',\n",
    "#             'US will provide coronavirus vaccine doses to about 100 countries over the next two years, three sources familiar with the matter told Reuters',\n",
    "#             'The Canadian minister for trade stated that the business sentiment was down 30% in Canada'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'positive', 'score': 0.7007909417152405},\n",
       " {'label': 'neutral', 'score': 0.8183404207229614},\n",
       " {'label': 'negative', 'score': 0.9747421145439148},\n",
       " {'label': 'neutral', 'score': 0.8846039175987244}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_list = ['Biden comes to Europe with a goodwill gesture, a planned announcement that the United States will donate 500 million dollars to Pfizer Inc/BioNTech (PFE.N)',\n",
    "            'US will provide coronavirus vaccine doses to about 100 countries over the next two years, three sources familiar with the matter told Reuters',\n",
    "            'The Canadian minister for trade stated that the business sentiment was down 30% in Canada',\n",
    "            'For your second question we would launch around F4 to F5 products next year and in the FY24 we would have similar plans']\n",
    "\n",
    "classifier(input_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 232
    },
    "id": "vmcZ8MI6CfWc",
    "outputId": "cf3d18a4-a37b-4cd3-9bf8-b0d39c53c343"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>positive</td>\n",
       "      <td>0.700791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neutral</td>\n",
       "      <td>0.818340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>negative</td>\n",
       "      <td>0.974742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>neutral</td>\n",
       "      <td>0.884604</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Label     Score\n",
       "0  positive  0.700791\n",
       "1   neutral  0.818340\n",
       "2  negative  0.974742\n",
       "3   neutral  0.884604"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_list = ['Biden comes to Europe with a goodwill gesture, a planned announcement that the United States will donate 500 million dollars to Pfizer Inc/BioNTech (PFE.N)',\n",
    "            'US will provide coronavirus vaccine doses to about 100 countries over the next two years, three sources familiar with the matter told Reuters',\n",
    "            'The Canadian minister for trade stated that the business sentiment was down 30% in Canada',\n",
    "            'For your second question we would launch around F4 to F5 products next year and in the FY24 we would have similar plans']\n",
    "\n",
    "num_sentences = len(input_list)\n",
    "out_matrix = pd.DataFrame(0, index=np.arange(num_sentences), columns=['Label', 'Score'])\n",
    "\n",
    "out_list = classifier(input_list)\n",
    "for idx, per_sentence_sentiment in enumerate(out_list):\n",
    "    out_matrix.iloc[idx, 0:] = (per_sentence_sentiment['label'], per_sentence_sentiment['score'])\n",
    "\n",
    "out_matrix  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3mEEtaGyCA3e"
   },
   "source": [
    "**Section 2**\n",
    "\n",
    "Identify the subsequence that has the highest semantic similarity to the original sequence\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "mLfarEjtLfwl"
   },
   "outputs": [],
   "source": [
    "# Load the spaCy model for POS tags\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "p8bpGpzkEBYx"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d985001f0e1e4c2c8e0611b20faeb4d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.18k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cf8ee6310e749b280b449bd21b6e6d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/10.1k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd7f6915b51848e9b8741275c038ba6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/571 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e79a81a76da44579845612c13e323695",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3384b10462604116b558c8c3e8fc7210",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/39.3k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b066062423ac4f1f8abb697f1df08639",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c32db0c8eb324a76976566b9199ba0c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4eed6b59811442e68a31a1fd33d3bd6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cff5834eba954b4fb4f63cea5dc9598b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25c8c5ed4bc64eae9d87759e0c92d5d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d10ddfff66e84c31ba58e4e28c22c523",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/363 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f206d30cc04b4bf9b617d4cf91191769",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/13.1k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a2a5b65c5034ba8a5f0d75a2190dee8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "756f6cdb70324a698a4f79911e787ad0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Instantiate SBERT\n",
    "sentence_model = SentenceTransformer('all-mpnet-base-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "OcY75tC9SInV"
   },
   "outputs": [],
   "source": [
    "orig_corpus = ['For your second question we would launch around 4 to 5 products next year and in the FY24 we would have similar plans']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IqWo8lsmnHDK"
   },
   "source": [
    "Section 2.1 -- Convert numbers to strings so that they are not removed during the generation of n-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEXT For  TOKEN ADP\n",
      "TEXT your  TOKEN PRON\n",
      "TEXT second  TOKEN ADJ\n",
      "TEXT question  TOKEN NOUN\n",
      "TEXT we  TOKEN PRON\n",
      "TEXT would  TOKEN AUX\n",
      "TEXT launch  TOKEN VERB\n",
      "TEXT around  TOKEN ADV\n",
      "TEXT 4  TOKEN NUM\n",
      "TEXT to  TOKEN PART\n",
      "TEXT 5  TOKEN NUM\n",
      "TEXT products  TOKEN NOUN\n",
      "TEXT next  TOKEN ADJ\n",
      "TEXT year  TOKEN NOUN\n",
      "TEXT and  TOKEN CCONJ\n",
      "TEXT in  TOKEN ADP\n",
      "TEXT the  TOKEN DET\n",
      "TEXT FY24  TOKEN NOUN\n",
      "TEXT we  TOKEN PRON\n",
      "TEXT would  TOKEN AUX\n",
      "TEXT have  TOKEN VERB\n",
      "TEXT similar  TOKEN ADJ\n",
      "TEXT plans  TOKEN NOUN\n"
     ]
    }
   ],
   "source": [
    "a = nlp(orig_corpus[0])\n",
    "for _ in a:\n",
    "    print('TEXT', _.text, ' TOKEN', _.pos_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 771
    },
    "id": "yVnCrZ_ER4JE",
    "outputId": "d24585e6-6b48-4bd9-df80-69aea88e7b5a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokens For your second question we would launch around 4 to 5 products next year and in the FY24 we would have similar plans\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>POS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>For</td>\n",
       "      <td>ADP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>your</td>\n",
       "      <td>PRON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>second</td>\n",
       "      <td>ADJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>question</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>we</td>\n",
       "      <td>PRON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>would</td>\n",
       "      <td>AUX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>launch</td>\n",
       "      <td>VERB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>around</td>\n",
       "      <td>ADV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4</td>\n",
       "      <td>NUM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>to</td>\n",
       "      <td>PART</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5</td>\n",
       "      <td>NUM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>products</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>next</td>\n",
       "      <td>ADJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>year</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>and</td>\n",
       "      <td>CCONJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>in</td>\n",
       "      <td>ADP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>the</td>\n",
       "      <td>DET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>FY24</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>we</td>\n",
       "      <td>PRON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>would</td>\n",
       "      <td>AUX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>have</td>\n",
       "      <td>VERB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>similar</td>\n",
       "      <td>ADJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>plans</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Text    POS\n",
       "0        For    ADP\n",
       "1       your   PRON\n",
       "2     second    ADJ\n",
       "3   question   NOUN\n",
       "4         we   PRON\n",
       "5      would    AUX\n",
       "6     launch   VERB\n",
       "7     around    ADV\n",
       "8          4    NUM\n",
       "9         to   PART\n",
       "10         5    NUM\n",
       "11  products   NOUN\n",
       "12      next    ADJ\n",
       "13      year   NOUN\n",
       "14       and  CCONJ\n",
       "15        in    ADP\n",
       "16       the    DET\n",
       "17      FY24   NOUN\n",
       "18        we   PRON\n",
       "19     would    AUX\n",
       "20      have   VERB\n",
       "21   similar    ADJ\n",
       "22     plans   NOUN"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Infer numbers using POS tags for conversion to character strings\n",
    "corpus_tokens = nlp(orig_corpus[0])\n",
    "print('tokens', corpus_tokens)\n",
    "col_names = ['Text', 'POS']\n",
    "output_df = pd.DataFrame([], columns = col_names)\n",
    "\n",
    "for token in corpus_tokens:\n",
    "    inlist = pd.DataFrame([[token.text, token.pos_]], columns=col_names)\n",
    "    output_df = pd.concat([output_df, inlist], ignore_index=True)\n",
    "\n",
    "output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "ooF8MmciTALZ",
    "outputId": "e510a9f0-1631-469b-ba17-5543cdefe397"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 8 10]\n",
      "        Text    POS\n",
      "0        For    ADP\n",
      "1       your   PRON\n",
      "2     second    ADJ\n",
      "3   question   NOUN\n",
      "4         we   PRON\n",
      "5      would    AUX\n",
      "6     launch   VERB\n",
      "7     around    ADV\n",
      "8         F4    NUM\n",
      "9         to   PART\n",
      "10        F5    NUM\n",
      "11  products   NOUN\n",
      "12      next    ADJ\n",
      "13      year   NOUN\n",
      "14       and  CCONJ\n",
      "15        in    ADP\n",
      "16       the    DET\n",
      "17      FY24   NOUN\n",
      "18        we   PRON\n",
      "19     would    AUX\n",
      "20      have   VERB\n",
      "21   similar    ADJ\n",
      "22     plans   NOUN\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'For your second question we would launch around F4 to F5 products next year and in the FY24 we would have similar plans'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_idx = np.where(output_df['POS'] == 'NUM')[0]\n",
    "print(num_idx)\n",
    "\n",
    "output_df.iloc[num_idx, 0]  = 'F' + output_df.iloc[num_idx, 0]\n",
    "print(output_df)\n",
    "\n",
    "revised_corpus = output_df['Text'].str.cat(sep=' ')\n",
    "revised_corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cAl3o_whn8He"
   },
   "source": [
    "Section 2.2 -- Generate n-grams and estimate the similarity between the n-grams and the original sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]]\n",
      "['around f4 to f5 products next year and in the fy24'\n",
      " 'around f4 to f5 products next year and in the fy24 we'\n",
      " 'around f4 to f5 products next year and in the fy24 we would'\n",
      " 'f4 to f5 products next year and in the fy24 we'\n",
      " 'f4 to f5 products next year and in the fy24 we would'\n",
      " 'f4 to f5 products next year and in the fy24 we would have'\n",
      " 'f5 products next year and in the fy24 we would have'\n",
      " 'f5 products next year and in the fy24 we would have similar'\n",
      " 'f5 products next year and in the fy24 we would have similar plans'\n",
      " 'for your second question we would launch around f4 to f5'\n",
      " 'for your second question we would launch around f4 to f5 products'\n",
      " 'for your second question we would launch around f4 to f5 products next'\n",
      " 'launch around f4 to f5 products next year and in the'\n",
      " 'launch around f4 to f5 products next year and in the fy24'\n",
      " 'launch around f4 to f5 products next year and in the fy24 we'\n",
      " 'next year and in the fy24 we would have similar plans'\n",
      " 'products next year and in the fy24 we would have similar'\n",
      " 'products next year and in the fy24 we would have similar plans'\n",
      " 'question we would launch around f4 to f5 products next year'\n",
      " 'question we would launch around f4 to f5 products next year and'\n",
      " 'question we would launch around f4 to f5 products next year and in'\n",
      " 'second question we would launch around f4 to f5 products next'\n",
      " 'second question we would launch around f4 to f5 products next year'\n",
      " 'second question we would launch around f4 to f5 products next year and'\n",
      " 'to f5 products next year and in the fy24 we would'\n",
      " 'to f5 products next year and in the fy24 we would have'\n",
      " 'to f5 products next year and in the fy24 we would have similar'\n",
      " 'we would launch around f4 to f5 products next year and'\n",
      " 'we would launch around f4 to f5 products next year and in'\n",
      " 'we would launch around f4 to f5 products next year and in the'\n",
      " 'would launch around f4 to f5 products next year and in'\n",
      " 'would launch around f4 to f5 products next year and in the'\n",
      " 'would launch around f4 to f5 products next year and in the fy24'\n",
      " 'your second question we would launch around f4 to f5 products'\n",
      " 'your second question we would launch around f4 to f5 products next'\n",
      " 'your second question we would launch around f4 to f5 products next year']\n"
     ]
    }
   ],
   "source": [
    "a = CountVectorizer(ngram_range=(11,13))\n",
    "b = a.fit_transform([revised_corpus])\n",
    "c = a.get_feature_names_out()\n",
    "print(b.toarray())\n",
    "print(c)\n",
    "# CountVectorizer(ngram_range=(11,13))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H1DIZGblCOrg",
    "outputId": "903c493e-6d65-4ebf-9f11-17e9b6fe6e4e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aum/Desktop/projects/con_trans_summary/con_summary_env/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate n-grams (tokens) of a predefined size from a single sentence\n",
    "# corpus = ['For your second question we would launch around 4 to 5 products next year and in the FY24 we would have similar plans']\n",
    "\n",
    "# Modify numbers in the sentence using the prefix \"F\"\n",
    "# corpus = ['For your second question we would launch around F4 to F5 products next year and in the FY24 we would have similar plans']\n",
    "corpus = [revised_corpus]\n",
    "vectorizer = CountVectorizer(ngram_range=(11,13))\n",
    "temp = vectorizer.fit_transform(corpus)\n",
    "sub_sequence_list = vectorizer.get_feature_names()\n",
    "\n",
    "# for list_element in sub_sequence_list:\n",
    "#   print(list_element)\n",
    "\n",
    "len(sub_sequence_list)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vWTN9vRZn1Go",
    "outputId": "58d331af-32bb-481e-a12b-4939dac45564"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['around f4 to f5 products next year and in the fy24',\n",
       " 'around f4 to f5 products next year and in the fy24 we',\n",
       " 'around f4 to f5 products next year and in the fy24 we would',\n",
       " 'f4 to f5 products next year and in the fy24 we',\n",
       " 'f4 to f5 products next year and in the fy24 we would',\n",
       " 'f4 to f5 products next year and in the fy24 we would have',\n",
       " 'f5 products next year and in the fy24 we would have',\n",
       " 'f5 products next year and in the fy24 we would have similar',\n",
       " 'f5 products next year and in the fy24 we would have similar plans',\n",
       " 'for your second question we would launch around f4 to f5',\n",
       " 'for your second question we would launch around f4 to f5 products',\n",
       " 'for your second question we would launch around f4 to f5 products next',\n",
       " 'launch around f4 to f5 products next year and in the',\n",
       " 'launch around f4 to f5 products next year and in the fy24',\n",
       " 'launch around f4 to f5 products next year and in the fy24 we',\n",
       " 'next year and in the fy24 we would have similar plans',\n",
       " 'products next year and in the fy24 we would have similar',\n",
       " 'products next year and in the fy24 we would have similar plans',\n",
       " 'question we would launch around f4 to f5 products next year',\n",
       " 'question we would launch around f4 to f5 products next year and',\n",
       " 'question we would launch around f4 to f5 products next year and in',\n",
       " 'second question we would launch around f4 to f5 products next',\n",
       " 'second question we would launch around f4 to f5 products next year',\n",
       " 'second question we would launch around f4 to f5 products next year and',\n",
       " 'to f5 products next year and in the fy24 we would',\n",
       " 'to f5 products next year and in the fy24 we would have',\n",
       " 'to f5 products next year and in the fy24 we would have similar',\n",
       " 'we would launch around f4 to f5 products next year and',\n",
       " 'we would launch around f4 to f5 products next year and in',\n",
       " 'we would launch around f4 to f5 products next year and in the',\n",
       " 'would launch around f4 to f5 products next year and in',\n",
       " 'would launch around f4 to f5 products next year and in the',\n",
       " 'would launch around f4 to f5 products next year and in the fy24',\n",
       " 'your second question we would launch around f4 to f5 products',\n",
       " 'your second question we would launch around f4 to f5 products next',\n",
       " 'your second question we would launch around f4 to f5 products next year']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_sequence_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "T4Q1V_V2D6ma"
   },
   "outputs": [],
   "source": [
    "# Calculate pairwise cosine similarity between elements in the query list and passage list\n",
    "# Out[i][j] corresponds to the cosine similarity between query_list[i] and passagelist[j]\n",
    "query_embedding = sentence_model.encode(corpus)\n",
    "passage_embedding = sentence_model.encode(sub_sequence_list)\n",
    "similarity_list =  util.cos_sim(query_embedding, passage_embedding).numpy()\n",
    "# similarity_list\n",
    "\n",
    "# Sort in ascending order and obtain the top 3 subsequences\n",
    "top_3_idx = np.argsort(similarity_list)[0, -3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([22, 23, 35])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_3_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "ZdfYgZSVG4h5",
    "outputId": "faae4691-a228-4f9e-e379-bcc72b42331d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence</th>\n",
       "      <th>cosine_similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>around f4 to f5 products next year and in the ...</td>\n",
       "      <td>0.779239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>around f4 to f5 products next year and in the ...</td>\n",
       "      <td>0.808505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>around f4 to f5 products next year and in the ...</td>\n",
       "      <td>0.827823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>f4 to f5 products next year and in the fy24 we</td>\n",
       "      <td>0.789200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>f4 to f5 products next year and in the fy24 we...</td>\n",
       "      <td>0.777601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>f4 to f5 products next year and in the fy24 we...</td>\n",
       "      <td>0.750036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>f5 products next year and in the fy24 we would...</td>\n",
       "      <td>0.726326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>f5 products next year and in the fy24 we would...</td>\n",
       "      <td>0.768127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>f5 products next year and in the fy24 we would...</td>\n",
       "      <td>0.851965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>for your second question we would launch aroun...</td>\n",
       "      <td>0.501838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>for your second question we would launch aroun...</td>\n",
       "      <td>0.847248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>for your second question we would launch aroun...</td>\n",
       "      <td>0.890803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>launch around f4 to f5 products next year and ...</td>\n",
       "      <td>0.811803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>launch around f4 to f5 products next year and ...</td>\n",
       "      <td>0.839995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>launch around f4 to f5 products next year and ...</td>\n",
       "      <td>0.855114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>next year and in the fy24 we would have simila...</td>\n",
       "      <td>0.629730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>products next year and in the fy24 we would ha...</td>\n",
       "      <td>0.766323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>products next year and in the fy24 we would ha...</td>\n",
       "      <td>0.843670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>question we would launch around f4 to f5 produ...</td>\n",
       "      <td>0.880684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>question we would launch around f4 to f5 produ...</td>\n",
       "      <td>0.889197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>question we would launch around f4 to f5 produ...</td>\n",
       "      <td>0.891530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>second question we would launch around f4 to f...</td>\n",
       "      <td>0.836455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>second question we would launch around f4 to f...</td>\n",
       "      <td>0.918208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>second question we would launch around f4 to f...</td>\n",
       "      <td>0.920358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>to f5 products next year and in the fy24 we would</td>\n",
       "      <td>0.772237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>to f5 products next year and in the fy24 we wo...</td>\n",
       "      <td>0.738631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>to f5 products next year and in the fy24 we wo...</td>\n",
       "      <td>0.774842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>we would launch around f4 to f5 products next ...</td>\n",
       "      <td>0.880877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>we would launch around f4 to f5 products next ...</td>\n",
       "      <td>0.877827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>we would launch around f4 to f5 products next ...</td>\n",
       "      <td>0.882530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>would launch around f4 to f5 products next yea...</td>\n",
       "      <td>0.850271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>would launch around f4 to f5 products next yea...</td>\n",
       "      <td>0.854084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>would launch around f4 to f5 products next yea...</td>\n",
       "      <td>0.881129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>your second question we would launch around f4...</td>\n",
       "      <td>0.848846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>your second question we would launch around f4...</td>\n",
       "      <td>0.878546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>your second question we would launch around f4...</td>\n",
       "      <td>0.946437</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             sequence  cosine_similarity\n",
       "0   around f4 to f5 products next year and in the ...           0.779239\n",
       "1   around f4 to f5 products next year and in the ...           0.808505\n",
       "2   around f4 to f5 products next year and in the ...           0.827823\n",
       "3      f4 to f5 products next year and in the fy24 we           0.789200\n",
       "4   f4 to f5 products next year and in the fy24 we...           0.777601\n",
       "5   f4 to f5 products next year and in the fy24 we...           0.750036\n",
       "6   f5 products next year and in the fy24 we would...           0.726326\n",
       "7   f5 products next year and in the fy24 we would...           0.768127\n",
       "8   f5 products next year and in the fy24 we would...           0.851965\n",
       "9   for your second question we would launch aroun...           0.501838\n",
       "10  for your second question we would launch aroun...           0.847248\n",
       "11  for your second question we would launch aroun...           0.890803\n",
       "12  launch around f4 to f5 products next year and ...           0.811803\n",
       "13  launch around f4 to f5 products next year and ...           0.839995\n",
       "14  launch around f4 to f5 products next year and ...           0.855114\n",
       "15  next year and in the fy24 we would have simila...           0.629730\n",
       "16  products next year and in the fy24 we would ha...           0.766323\n",
       "17  products next year and in the fy24 we would ha...           0.843670\n",
       "18  question we would launch around f4 to f5 produ...           0.880684\n",
       "19  question we would launch around f4 to f5 produ...           0.889197\n",
       "20  question we would launch around f4 to f5 produ...           0.891530\n",
       "21  second question we would launch around f4 to f...           0.836455\n",
       "22  second question we would launch around f4 to f...           0.918208\n",
       "23  second question we would launch around f4 to f...           0.920358\n",
       "24  to f5 products next year and in the fy24 we would           0.772237\n",
       "25  to f5 products next year and in the fy24 we wo...           0.738631\n",
       "26  to f5 products next year and in the fy24 we wo...           0.774842\n",
       "27  we would launch around f4 to f5 products next ...           0.880877\n",
       "28  we would launch around f4 to f5 products next ...           0.877827\n",
       "29  we would launch around f4 to f5 products next ...           0.882530\n",
       "30  would launch around f4 to f5 products next yea...           0.850271\n",
       "31  would launch around f4 to f5 products next yea...           0.854084\n",
       "32  would launch around f4 to f5 products next yea...           0.881129\n",
       "33  your second question we would launch around f4...           0.848846\n",
       "34  your second question we would launch around f4...           0.878546\n",
       "35  your second question we would launch around f4...           0.946437"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp_array = pd.DataFrame({'sequence':sub_sequence_list, 'cosine_similarity':similarity_list[0, :]})\n",
    "imp_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 476
    },
    "id": "ijDQT3OzHZyi",
    "outputId": "eab735fa-d00c-4e72-b5da-9f1033b89438"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "your second question we would launch around f4 to f5 products next year\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>POS</th>\n",
       "      <th>STOPWORD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>your</td>\n",
       "      <td>PRON</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>second</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>question</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>we</td>\n",
       "      <td>PRON</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>would</td>\n",
       "      <td>AUX</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>launch</td>\n",
       "      <td>VERB</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>around</td>\n",
       "      <td>ADP</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>f4</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>to</td>\n",
       "      <td>PART</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>f5</td>\n",
       "      <td>VERB</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>products</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>next</td>\n",
       "      <td>ADP</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>year</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Text    POS STOPWORD\n",
       "0       your   PRON     True\n",
       "1     second    ADJ    False\n",
       "2   question   NOUN    False\n",
       "3         we   PRON     True\n",
       "4      would    AUX     True\n",
       "5     launch   VERB    False\n",
       "6     around    ADP     True\n",
       "7         f4  PROPN    False\n",
       "8         to   PART     True\n",
       "9         f5   VERB    False\n",
       "10  products   NOUN    False\n",
       "11      next    ADP     True\n",
       "12      year   NOUN    False"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use POS tag to determine the start of the best subsequence\n",
    "best_sentence = imp_array.iloc[top_3_idx[2],0]\n",
    "print(best_sentence)\n",
    "\n",
    "# Obtain POS per token\n",
    "best_sent_tokens = nlp(best_sentence)\n",
    "col_names = ['Text', 'POS', 'STOPWORD']\n",
    "output_df = pd.DataFrame([], columns = col_names)\n",
    "\n",
    "for token in best_sent_tokens:\n",
    "    inlist = pd.DataFrame([[token.text, token.pos_, token.is_stop]], columns=col_names)\n",
    "    output_df = pd.concat([output_df, inlist], ignore_index=True)\n",
    "    \n",
    "output_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "64zOm6ybqrZP"
   },
   "source": [
    "Section 2.3 -- Potentially use the locations of \"verbs\" and \"stopwords\" to generate bullet points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "fH8h3y17qo09",
    "outputId": "846f0135-99ce-4cc0-f39b-c49524b55cae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{9, 5}\n",
      "[ 0  3  4  6  8 11]\n",
      "[5, 9]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'launch around f4 to f5 products next year'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "verb_pos = np.where(output_df['POS'] == 'VERB')[0]\n",
    "print(set(verb_pos))\n",
    "stop_pos = np.where(output_df['STOPWORD'] == True)[0]\n",
    "print(stop_pos)\n",
    "first_verb = list(set(verb_pos) - set(stop_pos))\n",
    "first_verb.reverse()  # Reversing as difference in set reverses the positions\n",
    "print(first_verb)\n",
    "output_df.iloc[first_verb[0]:, 0].str.cat(sep=' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T3n_UDN1jbfn"
   },
   "source": [
    "**Section 3**\n",
    "\n",
    "Use Maximal Marginal Relevance (MMR) metric to identify the most distinct subsequences from the same sequence/sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "CZupxupfjbPb"
   },
   "outputs": [],
   "source": [
    "def mmr(in_sequence_list, in_best_sequence, in_query, in_alpha, in_count_elements):\n",
    "  num_elements = min(in_count_elements, len(in_sequence_list))\n",
    "\n",
    "  # Ensure that the original lists are not modified\n",
    "  rem_sequence_list = in_sequence_list.copy()\n",
    "  current_list = in_best_sequence.copy()\n",
    "\n",
    "  query_embedding = sentence_model.encode(in_query)\n",
    "\n",
    "  # Add new elements to 'current_list'\n",
    "  for idx in range(num_elements):\n",
    "    print(idx)\n",
    "    passage_embedding = sentence_model.encode(rem_sequence_list)\n",
    "    current_list_embedding = sentence_model.encode(current_list)\n",
    "\n",
    "    # sim(D_i, Q)\n",
    "    seq_to_query_sim = util.cos_sim(query_embedding, passage_embedding).numpy()\n",
    "\n",
    "    # sim(D_i, D_j)\n",
    "    seq_to_seq_sim = util.cos_sim(passage_embedding, current_list_embedding).numpy()\n",
    "    seq_to_seq_max = np.amax(seq_to_seq_sim, axis=1) # Obtain the maximum per row or max[sim(D_i, D_j)]\n",
    "\n",
    "    # Identify the sequence with MMR\n",
    "    per_seq_val = in_alpha*seq_to_query_sim[0, :] - (1-in_alpha)*seq_to_seq_max\n",
    "    max_idx = np.argmax(per_seq_val)\n",
    "\n",
    "    # Add the best sequence to the current_list\n",
    "    current_list = current_list + [rem_sequence_list[max_idx]]\n",
    "    rem_sequence_list.pop(max_idx)\n",
    "\n",
    "  return current_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aqszP-zt5Pox"
   },
   "source": [
    "Section 3.1 -- Test MMR function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Zf6LQPaVsVJ5",
    "outputId": "985c241e-e369-4be9-e69a-bc8bed0743b7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the sequences into the best sequence and the remaining sequences\n",
    "best_sequence = [sub_sequence_list[top_3_idx[2]]]\n",
    "\n",
    "sequence_list = sub_sequence_list.copy()\n",
    "sequence_list.pop(top_3_idx[2])\n",
    "len(sequence_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PhvT9aeSxOOk"
   },
   "source": [
    "(1) If alpha=1, then subsequences with the highest match to the original query will be selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KPDi2EVIvNgM",
    "outputId": "5dae6df6-d2b4-467d-f86b-9e55af487dd6"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sequence_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_22953/714704202.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmmr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequence_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_sequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrevised_corpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'sequence_list' is not defined"
     ]
    }
   ],
   "source": [
    "mmr(sequence_list, best_sequence, revised_corpus, 1, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9jVAG0CNvbBX",
    "outputId": "a1650864-27d8-4724-9965-a999bb26413e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "your second question we would launch around f4 to f5 products next year\n",
      "second question we would launch around f4 to f5 products next year and\n",
      "second question we would launch around f4 to f5 products next year\n",
      "question we would launch around f4 to f5 products next year and in\n"
     ]
    }
   ],
   "source": [
    "zz = imp_array.sort_values(by=['cosine_similarity'], ascending=False, ignore_index=True)\n",
    "for idx in range(4):\n",
    "  print(zz['sequence'][idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zl9XjOWLxlep"
   },
   "source": [
    "(2) If alpha=0, then subsequences with the lowest match to the existing subsequences will be selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "VyOxXgrQx2P-"
   },
   "outputs": [],
   "source": [
    "temp_1 = sentence_model.encode(best_sequence)\n",
    "temp_2 = sentence_model.encode(sequence_list)\n",
    "temp_3 = util.cos_sim(temp_1, temp_2).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I_gyeqizzDvJ",
    "outputId": "20fa9e2c-2d67-457c-e0e3-4ec7472edf90"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(-temp_3[0, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "TIqOqLaLzRvv",
    "outputId": "fbab34ec-8338-4be5-81c0-6c70f8dfbb59"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'next year and in the fy24 we would have similar plans'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence_list[15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CVTnKjDZptMP",
    "outputId": "5c396fb3-c11a-4162-8e20-20f1f36f447a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['your second question we would launch around f4 to f5 products next year',\n",
       " 'next year and in the fy24 we would have similar plans',\n",
       " 'for your second question we would launch around f4 to f5',\n",
       " 'products next year and in the fy24 we would have similar']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mmr(sequence_list, best_sequence, revised_corpus, 0, 3)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Code_Snippets_NLU.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "12466f790b01845891e8c54f2878097070b87efd364ef8a7c7054cc189b73841"
  },
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit ('con_summary_env': venv)",
   "language": "python",
   "name": "python391jvsc74a57bd012466f790b01845891e8c54f2878097070b87efd364ef8a7c7054cc189b73841"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
