{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CAUJS8dwS_pn"
   },
   "source": [
    "**Understanding BERT embeddings based on the code shared by Chris McCormick**\n",
    "\n",
    "https://mccormickml.com/2019/05/14/BERT-word-embeddings-tutorial/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 8252,
     "status": "ok",
     "timestamp": 1635313725750,
     "user": {
      "displayName": "Vivek Jayaswal",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "07386092584236149418"
     },
     "user_tz": -330
    },
    "id": "M1aGpumHEn5f"
   },
   "outputs": [],
   "source": [
    "!pip install -q transformers\n",
    "!pip install -q sentence_transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 12775,
     "status": "ok",
     "timestamp": 1635313738522,
     "user": {
      "displayName": "Vivek Jayaswal",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "07386092584236149418"
     },
     "user_tz": -330
    },
    "id": "05UlCDSsDcxy"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizerFast, BertModel # Use BertTokenizerFast to ensure that words_ids() can be used\n",
    "from sentence_transformers import util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1635313738523,
     "user": {
      "displayName": "Vivek Jayaswal",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "07386092584236149418"
     },
     "user_tz": -330
    },
    "id": "m3zM96LkWC1C"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1635313738525,
     "user": {
      "displayName": "Vivek Jayaswal",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "07386092584236149418"
     },
     "user_tz": -330
    },
    "id": "8EKPIwL4RTFJ",
    "outputId": "1774dcd1-e14f-4eda-840f-013c7b9677c5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/aum/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6556,
     "status": "ok",
     "timestamp": 1635313745071,
     "user": {
      "displayName": "Vivek Jayaswal",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "07386092584236149418"
     },
     "user_tz": -330
    },
    "id": "KS1nsUpHD6By",
    "outputId": "bc602ddc-7f82-4aa6-d27f-9de6d9a97065"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████████████████████████████████████████████| 29.0/29.0 [00:00<00:00, 13.1kB/s]\n",
      "Downloading: 100%|█████████████████████████████████████████████████████| 570/570 [00:00<00:00, 262kB/s]\n",
      "Downloading: 100%|██████████████████████████████████████████████████| 436M/436M [01:44<00:00, 4.17MB/s]\n",
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the tokenizer and model\n",
    "tokenizer = BertTokenizerFast.from_pretrained(\"bert-base-cased\")\n",
    "\n",
    "model = BertModel.from_pretrained(\"bert-base-cased\", output_hidden_states=True)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HVfO72jKW27u"
   },
   "source": [
    "#### Step 1: Map a word of interest to the set of tokens corresponding to it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 42,
     "status": "ok",
     "timestamp": 1635313745071,
     "user": {
      "displayName": "Vivek Jayaswal",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "07386092584236149418"
     },
     "user_tz": -330
    },
    "id": "ZTTP-32eHmtj",
    "outputId": "951be855-268f-4090-b8ec-bfc5d5de330e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'like', 'cookie', \"'\", 's']\n",
      "{'input_ids': [101, 146, 1176, 25413, 112, 188, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1]}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, 0, 1, 2, 3, 4, None]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scenario 1: A word with a punctuation is split into multiple tokens and \n",
    "# these tokens are treated as separate words\n",
    "trial_sent_1 = \"I like cookie's\"\n",
    "\n",
    "current_token_list = tokenizer.tokenize(trial_sent_1)\n",
    "print(current_token_list)\n",
    "current_encoding = tokenizer.encode_plus(trial_sent_1)\n",
    "print(current_encoding)\n",
    "current_encoding.word_ids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 31,
     "status": "ok",
     "timestamp": 1635313745072,
     "user": {
      "displayName": "Vivek Jayaswal",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "07386092584236149418"
     },
     "user_tz": -330
    },
    "id": "ala53X5yXOhs",
    "outputId": "936bd136-5cb7-4c12-8e00-d424ccc86bd0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'like', 'cook', '##ys']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, 0, 1, 2, 2, None]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scenario 2: A word without a punctuation is split into multiple tokens and \n",
    "# these tokens are treated as a single word\n",
    "trial_sent_2 = \"I like cookys\"\n",
    "\n",
    "current_token_list = tokenizer.tokenize(trial_sent_2)\n",
    "print(current_token_list)\n",
    "current_encoding = tokenizer.encode_plus(trial_sent_2)\n",
    "current_encoding.word_ids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 29,
     "status": "ok",
     "timestamp": 1635313745073,
     "user": {
      "displayName": "Vivek Jayaswal",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "07386092584236149418"
     },
     "user_tz": -330
    },
    "id": "Z3ajzw4TGiYF",
    "outputId": "81469982-b82c-487e-c0f6-f53bc788c929"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['After',\n",
       " 'stealing',\n",
       " 'money',\n",
       " 'from',\n",
       " 'the',\n",
       " 'bank',\n",
       " 'vault',\n",
       " ',',\n",
       " 'the',\n",
       " 'bank',\n",
       " 'r',\n",
       " '##ob',\n",
       " '##ber',\n",
       " 'was',\n",
       " 'seen',\n",
       " 'fishing',\n",
       " 'on',\n",
       " 'the',\n",
       " 'Mississippi',\n",
       " 'river',\n",
       " 'bank']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scenario 3: Index of 'word of interest' needs to be identified using the location of the word or \n",
    "# subwords post tokenization\n",
    "trial_sent_3 = \"After stealing money from the bank vault, the bank robber was seen fishing on the Mississippi river bank\"\n",
    "\n",
    "current_token_list = tokenizer.tokenize(trial_sent_3)\n",
    "current_token_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 27,
     "status": "ok",
     "timestamp": 1635313745075,
     "user": {
      "displayName": "Vivek Jayaswal",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "07386092584236149418"
     },
     "user_tz": -330
    },
    "id": "U7ijZUNlHXXS",
    "outputId": "a7e02481-e16d-48ea-96bf-244d226d22f6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['After',\n",
       " 'stealing',\n",
       " 'money',\n",
       " 'from',\n",
       " 'the',\n",
       " 'bank',\n",
       " 'vault,',\n",
       " 'the',\n",
       " 'bank',\n",
       " 'robber',\n",
       " 'was',\n",
       " 'seen',\n",
       " 'fishing',\n",
       " 'on',\n",
       " 'the',\n",
       " 'Mississippi',\n",
       " 'river',\n",
       " 'bank']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Python's default string split is different from that obtained using BERT tokenizer\n",
    "# Evaluate the use NLTK's tokenizer\n",
    "trial_sent_3.split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 25,
     "status": "ok",
     "timestamp": 1635313745076,
     "user": {
      "displayName": "Vivek Jayaswal",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "07386092584236149418"
     },
     "user_tz": -330
    },
    "id": "tQgb5i_zKemw",
    "outputId": "3005fbc8-7fdb-45c0-cb19-6e81328604ca"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['After',\n",
       " 'stealing',\n",
       " 'money',\n",
       " 'from',\n",
       " 'the',\n",
       " 'bank',\n",
       " 'vault',\n",
       " ',',\n",
       " 'the',\n",
       " 'bank',\n",
       " 'robber',\n",
       " 'was',\n",
       " 'seen',\n",
       " 'fishing',\n",
       " 'on',\n",
       " 'the',\n",
       " 'Mississippi',\n",
       " 'river',\n",
       " 'bank']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.tokenize.word_tokenize(trial_sent_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_YQI5UsiZiPg"
   },
   "source": [
    "#### Step 2: Obtain token embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 22,
     "status": "ok",
     "timestamp": 1635313745076,
     "user": {
      "displayName": "Vivek Jayaswal",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "07386092584236149418"
     },
     "user_tz": -330
    },
    "id": "v0QSudfGZ32e",
    "outputId": "7def1ec6-ba42-4894-fb3c-266091b70c26"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'love', 'cookies']\n",
      "{'input_ids': [101, 146, 1567, 18621, 102], 'token_type_ids': [0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1]}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, 0, 1, 2, None]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual_sent = \"I love cookies\"\n",
    "current_token_list = tokenizer.tokenize(actual_sent)\n",
    "print(current_token_list)\n",
    "\n",
    "current_encoding = tokenizer.encode_plus(actual_sent)\n",
    "print(current_encoding)\n",
    "current_encoding.word_ids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1635313745077,
     "user": {
      "displayName": "Vivek Jayaswal",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "07386092584236149418"
     },
     "user_tz": -330
    },
    "id": "sERv9y0obF4J"
   },
   "outputs": [],
   "source": [
    "indexed_tokens = current_encoding['input_ids']\n",
    "segments_ids = [1] * len(indexed_tokens)\n",
    "\n",
    "# Convert inputs to PyTorch tensors\n",
    "tokens_tensor = torch.tensor([indexed_tokens])\n",
    "segments_tensors = torch.tensor([segments_ids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1635313745078,
     "user": {
      "displayName": "Vivek Jayaswal",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "07386092584236149418"
     },
     "user_tz": -330
    },
    "id": "3dEVM06WbptN",
    "outputId": "7b1c45ad-c71b-44be-9870-579077f561da",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 5])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(tokens_tensor.size())\n",
    "segments_tensors.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1635313745079,
     "user": {
      "displayName": "Vivek Jayaswal",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "07386092584236149418"
     },
     "user_tz": -330
    },
    "id": "5OBr_R2CY6t_"
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    outputs = model(tokens_tensor, segments_tensors)\n",
    "    hidden_states = outputs[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 676,
     "status": "ok",
     "timestamp": 1635313745738,
     "user": {
      "displayName": "Vivek Jayaswal",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "07386092584236149418"
     },
     "user_tz": -330
    },
    "id": "5DdvmGZUbj-e",
    "outputId": "95db2890-40a7-41bf-a4ac-b072d709e603"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tuple length = number of hidden layers (default = 12) + token embeddings (i.e. embeddings corresponding to the input layer)\n",
    "len(hidden_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 47,
     "status": "ok",
     "timestamp": 1635313745746,
     "user": {
      "displayName": "Vivek Jayaswal",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "07386092584236149418"
     },
     "user_tz": -330
    },
    "id": "_BaSm0TyrpUX",
    "outputId": "1e2caa4d-cefb-4264-a1c8-79cd1f5ac612"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5, 768])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For a given layer, a tensor of size Batch x Number_Of_Tokens (including [CLS] and [SEP]) x Dimension\n",
    "hidden_states[0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 45,
     "status": "ok",
     "timestamp": 1635313745747,
     "user": {
      "displayName": "Vivek Jayaswal",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "07386092584236149418"
     },
     "user_tz": -330
    },
    "id": "PblyROiEsczG",
    "outputId": "d958d728-9a4f-4724-bd31-19ceeaf749c6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([13, 1, 5, 768])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_embeddings = torch.stack(hidden_states, dim=0)\n",
    "token_embeddings.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 42,
     "status": "ok",
     "timestamp": 1635313745747,
     "user": {
      "displayName": "Vivek Jayaswal",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "07386092584236149418"
     },
     "user_tz": -330
    },
    "id": "kiiX-EhEvJ7S",
    "outputId": "63a76888-47a1-4e94-c960-82cfa7bf8155"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([13, 5, 768])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove dimension 1 i.e. \"batches\"\n",
    "token_embeddings = torch.squeeze(token_embeddings, dim=1)\n",
    "token_embeddings.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 40,
     "status": "ok",
     "timestamp": 1635313745748,
     "user": {
      "displayName": "Vivek Jayaswal",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "07386092584236149418"
     },
     "user_tz": -330
    },
    "id": "_A1NEXGSvMWF",
    "outputId": "38299240-6562-4b4f-96ef-74f98e4031f2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 13, 768])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Swap dimensions 0 and 1.\n",
    "token_embeddings = token_embeddings.permute(1,0,2)\n",
    "token_embeddings.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.4496,  0.0977, -0.2074,  ...,  0.0578,  0.0406, -0.0951],\n",
       "        [ 0.2667, -0.0738, -0.1410,  ...,  0.0150,  0.0179, -0.0761],\n",
       "        [ 0.4117, -0.0251, -0.2122,  ...,  0.0632,  0.1492, -0.3645],\n",
       "        ...,\n",
       "        [ 0.5524,  0.5921, -0.4682,  ..., -0.3786,  0.5331,  0.0038],\n",
       "        [ 0.6583,  0.2964,  0.0800,  ..., -0.1478,  0.8567,  0.3803],\n",
       "        [ 0.4512,  0.0186,  0.0258,  ..., -0.1439,  0.3795,  0.0168]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_embeddings[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 40,
     "status": "ok",
     "timestamp": 1635313745749,
     "user": {
      "displayName": "Vivek Jayaswal",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "07386092584236149418"
     },
     "user_tz": -330
    },
    "id": "gIADSTn6vXO0",
    "outputId": "769d7711-08fd-4d7c-f01b-3b4de47e2461"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape is: 5 x 768\n"
     ]
    }
   ],
   "source": [
    "# Pooling strategy -- sum together the last four layers\n",
    "token_vecs_sum = []\n",
    "\n",
    "# For each token in the sentence...\n",
    "for token in token_embeddings:\n",
    "    sum_vec = torch.sum(token[-4:], dim=0) # returns column sum\n",
    "    token_vecs_sum.append(sum_vec)\n",
    "\n",
    "print ('Shape is: %d x %d' % (len(token_vecs_sum), len(token_vecs_sum[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 37,
     "status": "ok",
     "timestamp": 1635313745749,
     "user": {
      "displayName": "Vivek Jayaswal",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "07386092584236149418"
     },
     "user_tz": -330
    },
    "id": "2BN3SxOtLRW1",
    "outputId": "2d4fc499-c71c-439a-b13d-224f62ef7bea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 4, 768])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 768])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Direct implementation of the pooling strategy\n",
    "rev_token_embeddings = token_embeddings.detach().clone()\n",
    "rev_token_embeddings = rev_token_embeddings[:, -4:, :]\n",
    "print(rev_token_embeddings.size())\n",
    "\n",
    "rev_token_sum = torch.sum(rev_token_embeddings, dim=1)  # Adds the 4 layers\n",
    "rev_token_sum.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 34,
     "status": "ok",
     "timestamp": 1635313745750,
     "user": {
      "displayName": "Vivek Jayaswal",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "07386092584236149418"
     },
     "user_tz": -330
    },
    "id": "RAfb_lUCOcO_",
    "outputId": "b7ec901e-cee4-4d40-ab06-79bee28e9692"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.equal(rev_token_sum[0], token_vecs_sum[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_h0AzFVt-fA4"
   },
   "source": [
    "#### Step 3: Obtain the word embedding by pooling over the relevant token embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "executionInfo": {
     "elapsed": 31,
     "status": "ok",
     "timestamp": 1635313745750,
     "user": {
      "displayName": "Vivek Jayaswal",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "07386092584236149418"
     },
     "user_tz": -330
    },
    "id": "Jn9lBfew4VrX"
   },
   "outputs": [],
   "source": [
    "# If multiple tokens map to a single word, then obtain the mean of the relevant token embeddings\n",
    "# sentence_embedding = torch.mean(token_vecs, dim=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L48v67r4HJJ0"
   },
   "source": [
    "#### Step 4: Understand the contextual difference in the use of the word \"bank\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "executionInfo": {
     "elapsed": 32,
     "status": "ok",
     "timestamp": 1635313745751,
     "user": {
      "displayName": "Vivek Jayaswal",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "07386092584236149418"
     },
     "user_tz": -330
    },
    "id": "4qaUMcQSHSQS"
   },
   "outputs": [],
   "source": [
    "multiple_context_sent = \"After stealing money from the bank vault, the bank robber was seen fishing on the Mississippi river bank\"\n",
    "# multiple_context_sent = \"Location name and Person name\"\n",
    "\n",
    "current_encoding = tokenizer.encode_plus(multiple_context_sent)\n",
    "indexed_tokens = current_encoding['input_ids']\n",
    "segments_ids = [1] * len(indexed_tokens)\n",
    "\n",
    "# Convert inputs to PyTorch tensors\n",
    "tokens_tensor = torch.tensor([indexed_tokens])\n",
    "segments_tensors = torch.tensor([segments_ids])\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(tokens_tensor, segments_tensors)\n",
    "    hidden_states = outputs[2]\n",
    "\n",
    "token_embeddings = torch.stack(hidden_states, dim=0)\n",
    "token_embeddings = torch.squeeze(token_embeddings, dim=1)\n",
    "token_embeddings = token_embeddings.permute(1,0,2)\n",
    "\n",
    "# Pooling strategy -- sum together the last four layers\n",
    "token_vecs_sum = []\n",
    "\n",
    "# For each token in the sentence...\n",
    "for token in token_embeddings:\n",
    "    sum_vec = torch.sum(token[-4:], dim=0) # returns column sum\n",
    "    token_vecs_sum.append(sum_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 32,
     "status": "ok",
     "timestamp": 1635313745752,
     "user": {
      "displayName": "Vivek Jayaswal",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "07386092584236149418"
     },
     "user_tz": -330
    },
    "id": "s4u1iJ_RJomC",
    "outputId": "c1a70977-192f-4222-ca95-cf6fbfad467f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5,  9, 20])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add 1 to the values below as [CLS] token is not considered\n",
    "np.where(np.array(tokenizer.tokenize(multiple_context_sent)) == 'bank')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 30,
     "status": "ok",
     "timestamp": 1635313745752,
     "user": {
      "displayName": "Vivek Jayaswal",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "07386092584236149418"
     },
     "user_tz": -330
    },
    "id": "zeYy8lpXRLt4",
    "outputId": "24e3a91e-7326-413b-ae3d-58199afbe696"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3085\n",
      "3085\n",
      "3085\n"
     ]
    }
   ],
   "source": [
    "# Each occurence of the word \"bank\" has the same index\n",
    "for idx in [6, 10, 21]:\n",
    "    print(indexed_tokens[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 28,
     "status": "ok",
     "timestamp": 1635313745752,
     "user": {
      "displayName": "Vivek Jayaswal",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "07386092584236149418"
     },
     "user_tz": -330
    },
    "id": "i1lTBpMxKW_o",
    "outputId": "ee6afadf-6e31-442e-995a-5550c4bc036c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [CLS] + 21 + [SEP]\n",
    "len(token_vecs_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 27,
     "status": "ok",
     "timestamp": 1635313745753,
     "user": {
      "displayName": "Vivek Jayaswal",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "07386092584236149418"
     },
     "user_tz": -330
    },
    "id": "QX5TVX2rK448",
    "outputId": "9daa039a-b20c-4bcc-ecef-4846be9212d8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 768])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bank_tensors = torch.cat((torch.unsqueeze(token_vecs_sum[6], 0)\n",
    "                          , torch.unsqueeze(token_vecs_sum[10], 0)\n",
    "                          , torch.unsqueeze(token_vecs_sum[21], 0))\n",
    "                          , dim=0)\n",
    "bank_tensors.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 25,
     "status": "ok",
     "timestamp": 1635313745753,
     "user": {
      "displayName": "Vivek Jayaswal",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "07386092584236149418"
     },
     "user_tz": -330
    },
    "id": "k4RCgcN8M1S5",
    "outputId": "0c565a31-c164-4afb-9c29-5413427dd0ae"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.9078, 0.5361],\n",
       "        [0.9078, 1.0000, 0.5107],\n",
       "        [0.5361, 0.5107, 1.0000]])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# <bank vault, bank robber, river bank>\n",
    "# Context changes the similarity between the same word\n",
    "util.cos_sim(bank_tensors, bank_tensors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f9NOaB5BP6aa"
   },
   "source": [
    "#### Section 4: Non-context specific word embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "executionInfo": {
     "elapsed": 23,
     "status": "ok",
     "timestamp": 1635313745754,
     "user": {
      "displayName": "Vivek Jayaswal",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "07386092584236149418"
     },
     "user_tz": -330
    },
    "id": "4PrdNqfsQBXU"
   },
   "outputs": [],
   "source": [
    "single_word_sent = \"bank\"\n",
    "\n",
    "current_encoding = tokenizer.encode_plus(single_word_sent)\n",
    "indexed_tokens = current_encoding['input_ids']\n",
    "segments_ids = [1] * len(indexed_tokens)\n",
    "\n",
    "# Convert inputs to PyTorch tensors\n",
    "tokens_tensor = torch.tensor([indexed_tokens])\n",
    "segments_tensors = torch.tensor([segments_ids])\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(tokens_tensor, segments_tensors)\n",
    "    hidden_states = outputs[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 23,
     "status": "ok",
     "timestamp": 1635313745754,
     "user": {
      "displayName": "Vivek Jayaswal",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "07386092584236149418"
     },
     "user_tz": -330
    },
    "id": "M09JSKjjQv3A",
    "outputId": "bb4a28bf-476d-4cf6-9579-a8693377a701"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[101, 3085, 102]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Three indexes as [CLS] + word + [SEP]\n",
    "indexed_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1635313745754,
     "user": {
      "displayName": "Vivek Jayaswal",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "07386092584236149418"
     },
     "user_tz": -330
    },
    "id": "OScq7iVQQcIO",
    "outputId": "79cebf85-f1cc-46ce-fb0b-b6fb2e4450c7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 13, 768])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_embeddings = torch.stack(hidden_states, dim=0)\n",
    "token_embeddings = torch.squeeze(token_embeddings, dim=1)\n",
    "token_embeddings = token_embeddings.permute(1,0,2)\n",
    "token_embeddings.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.6800e+00, -3.8411e+00, -5.5064e-01, -1.2277e+00,  2.8083e+00,\n",
       "        -5.7303e-01,  1.2490e+00, -1.3138e+00, -1.2867e+00, -3.6897e+00,\n",
       "        -4.3411e-01,  2.6089e+00, -1.3374e+00,  4.5027e-01, -4.6955e+00,\n",
       "         1.5810e+00, -2.1483e+00,  1.4087e+00, -1.2810e+00,  8.5802e-01,\n",
       "        -3.5459e-01, -7.3232e-01,  1.6852e+00, -2.6272e+00, -5.2610e-01,\n",
       "         1.1292e-01,  5.4922e+00,  1.8765e+00,  1.9510e+00,  1.5943e+00,\n",
       "         1.8239e+00,  6.7557e-01,  9.5497e-01,  1.1036e+00, -3.7717e+00,\n",
       "        -1.2309e+00,  1.4484e+00, -2.3033e+00, -1.0131e+00,  3.8497e-01,\n",
       "         3.8491e+00,  4.3207e-01,  4.0658e+00, -3.9740e+00, -4.3068e-01,\n",
       "        -2.6316e-01,  7.8924e-01,  1.0620e+00, -2.4596e+00,  2.0776e+00,\n",
       "        -5.9122e-01, -4.6244e+00,  1.5487e+00,  4.7681e-01, -2.8546e+00,\n",
       "        -2.1733e+00, -2.3053e+00, -2.0281e-01, -1.9056e+00,  6.9816e-01,\n",
       "        -1.6894e+00, -1.6909e+00,  1.1839e+00,  3.6217e-01,  3.8176e-01,\n",
       "         6.3226e+00,  1.1985e+00,  2.2313e+00,  1.0518e+00, -2.9545e+00,\n",
       "        -1.5294e+00,  2.1426e+00,  1.3022e+00,  1.7427e+00, -4.8311e-01,\n",
       "        -1.6999e+00, -5.8323e-01, -7.2930e-01,  2.8160e+00, -7.0766e-02,\n",
       "         2.1294e+00, -7.8999e-01, -4.2151e-01, -2.3137e+00, -2.1343e-01,\n",
       "        -1.9097e+00, -8.6260e-01, -1.9631e+00, -2.5520e+00, -6.7627e-03,\n",
       "         2.1416e+00, -1.3232e-01, -6.6685e-01, -3.1111e+00, -4.5233e-01,\n",
       "        -9.6185e-01, -6.9897e-01, -3.0858e+00,  2.7841e+00,  2.5767e+00,\n",
       "         4.9866e-01, -2.6700e+00,  1.5170e-01, -3.7786e+00,  1.0921e-01,\n",
       "        -3.1468e+00, -1.8024e+00, -2.3259e+00,  7.8996e-01, -3.0691e+00,\n",
       "         1.4442e+00,  2.7546e+00,  2.7073e+00, -8.5778e-01,  1.7669e+00,\n",
       "         2.1365e-01, -3.7272e+00,  4.7141e+00, -3.3508e-01, -5.0509e+00,\n",
       "         6.0494e+00,  8.8888e-01,  8.7690e-01, -2.0400e+00, -2.8470e-01,\n",
       "        -1.4979e-01,  1.6840e+00,  6.5755e-01,  2.8027e+00, -2.1542e+00,\n",
       "        -3.2662e+00, -2.3073e+00, -2.4504e+00,  1.7969e+00,  1.1359e+00,\n",
       "         2.6652e+00, -2.9332e+00, -7.8878e-01, -9.8418e+00,  1.8693e+00,\n",
       "         1.2374e+00,  1.2836e-01, -2.9541e-02,  2.6273e-01, -1.5378e+00,\n",
       "         4.0192e+00, -2.7760e-01,  1.0400e+00, -1.1734e-01,  3.0384e-01,\n",
       "        -7.6577e-01, -9.6730e-01, -2.1806e+00, -1.0479e+00, -8.7806e-01,\n",
       "        -3.0560e+00,  1.6467e-01, -1.7221e+00,  2.1185e-01, -1.0703e+00,\n",
       "         3.4855e+00, -1.4687e+00, -1.1863e+00,  1.8499e+00,  9.4629e-02,\n",
       "        -5.4927e-01,  1.8488e-01,  9.8445e-01, -1.3791e+00,  4.3448e+00,\n",
       "         3.8301e-02,  3.5043e-01, -2.8325e+00,  1.0126e+00, -1.5781e+00,\n",
       "        -9.2525e-02, -1.3357e+00, -5.4353e-01,  3.4893e+00, -3.9128e-01,\n",
       "         1.9816e+00, -9.4952e-01,  2.4876e-01, -1.1317e-01,  2.7356e+00,\n",
       "         3.0108e+00, -4.6418e-01, -5.8558e-01, -2.5431e+00, -3.5061e+00,\n",
       "        -4.5894e-02, -3.4234e+00,  4.6360e-01, -3.9445e-01, -3.9996e-01,\n",
       "        -1.4941e+00, -1.5825e+00,  1.1949e+00,  2.6001e+00,  2.0681e+00,\n",
       "        -2.5283e+00, -1.6111e-01,  5.8479e-01,  2.5591e+00, -1.9071e+00,\n",
       "         2.1335e+00,  1.4343e+00,  9.6375e-01,  5.2155e-01, -1.4935e-01,\n",
       "         2.7430e+00, -1.6427e+00, -8.7328e-01,  6.1719e-01,  2.2821e+00,\n",
       "         6.5465e-01, -1.3005e+00, -1.6063e+00, -3.6246e-01, -3.7622e-01,\n",
       "        -2.5530e+00,  2.8984e-01, -1.1074e+00,  9.7048e-01,  3.5335e+00,\n",
       "        -2.5958e+00,  1.1949e-01,  3.6308e+00,  6.6112e-01,  1.2769e+00,\n",
       "         3.8663e+00, -1.8578e-01,  8.0094e-01, -2.9091e-01, -1.3845e+00,\n",
       "         2.3697e+00, -2.6733e+00, -2.4265e+00,  5.2168e-01,  5.3110e+00,\n",
       "         1.5910e+00,  1.9859e+00,  5.0080e-01, -1.3138e+00, -3.6919e+00,\n",
       "         1.6950e+00,  3.6543e+00,  3.1826e+00,  1.0696e-02,  2.2595e-01,\n",
       "        -3.3815e-01,  6.3525e-01, -2.8149e+00,  5.6333e+00,  2.3759e-01,\n",
       "         5.6020e+00,  3.2645e+00, -1.6414e+00, -3.1119e+00,  1.8683e+00,\n",
       "         2.3595e+00, -4.6484e+00,  1.6743e+00, -2.1985e+00, -1.8197e+00,\n",
       "        -4.4365e-01, -2.0179e+00,  3.9282e-01, -7.3480e-02, -2.1315e+00,\n",
       "        -2.1635e+00, -3.2824e+00, -3.4331e+00,  1.0352e+00,  1.1029e-01,\n",
       "         3.6693e-01, -2.1059e+00, -1.7166e+00,  3.4381e-02, -5.2951e-01,\n",
       "         2.1534e+00, -9.0647e-01, -5.4599e-01,  4.4574e-02, -1.9483e+00,\n",
       "         1.0854e+00,  3.5354e+00,  6.6235e-01,  2.0562e+00,  4.5610e+00,\n",
       "        -4.8347e-01, -1.7094e+00, -7.1666e-01,  3.9393e+00,  1.1191e+00,\n",
       "         1.2847e+00, -4.0785e+00, -8.1038e-02, -9.8487e-01,  1.5666e-02,\n",
       "         3.5789e-01, -3.1744e+00,  6.2488e-01,  7.5332e-01, -3.5028e+00,\n",
       "        -1.1263e+00, -3.2640e+00,  3.0862e+00, -2.0684e+00,  3.3572e-01,\n",
       "        -5.0364e-01,  1.0122e+00, -2.5431e+00, -1.3616e+00, -9.5202e-01,\n",
       "         5.9765e-02, -1.7399e+00,  3.7419e+00,  3.6385e+00, -1.4053e+00,\n",
       "         3.8491e+00, -2.0001e+00,  5.8751e-01,  5.2484e-01, -3.0964e+00,\n",
       "         3.3061e+00, -4.4222e+00, -3.4366e+00,  3.1176e+00,  1.6992e+00,\n",
       "        -7.7848e-02, -2.4145e+00,  3.1116e-02, -1.2644e+00, -2.9246e+00,\n",
       "         1.2934e+00,  7.7433e-01,  4.0358e-01, -1.9277e+00,  1.5541e+00,\n",
       "        -3.3763e-01, -1.4351e-01, -8.8600e-01,  4.1820e+00, -1.8439e+00,\n",
       "         2.2891e-01,  4.2669e-01,  6.5131e-01, -1.6193e+00, -2.6266e+00,\n",
       "        -3.4745e+00, -1.3808e+00, -1.6095e+00,  4.9546e+00,  3.1471e+00,\n",
       "         4.4117e+00,  1.3474e+00, -2.1080e+00,  1.7374e+00,  1.4776e+00,\n",
       "        -2.2531e+00, -5.2001e+00, -3.4952e-01,  1.2683e+00, -3.1669e-02,\n",
       "        -5.8212e-01, -2.1082e+00,  1.8195e+00,  2.2647e+00, -1.4029e+00,\n",
       "         1.1115e-01,  9.0761e-01,  3.7042e-01,  1.1033e+00, -7.6225e-01,\n",
       "        -1.8884e+00,  1.3006e+00,  2.0744e+00,  6.2654e-01, -2.9394e+00,\n",
       "         6.1331e-01,  1.2455e+00,  1.6873e+00, -8.0835e-01,  1.0303e+00,\n",
       "         2.1067e-01,  1.3597e+00,  5.6793e-01, -1.8673e+00,  1.5948e+00,\n",
       "        -2.3889e+00,  2.2620e+00,  1.1780e+00, -1.9260e+00,  1.5626e+00,\n",
       "         2.3751e-01, -1.4526e+00,  7.8993e-01,  3.5043e-01, -9.4382e-01,\n",
       "         1.0112e+00,  4.7587e-01,  1.7798e+00,  5.3902e+00, -2.5729e+00,\n",
       "        -3.3389e+00,  7.6616e-01, -3.6295e+00, -2.4764e-01,  2.6556e-01,\n",
       "         4.1223e+00, -1.2616e-01, -1.7779e+00,  2.0053e+00,  5.1013e-01,\n",
       "        -9.6911e-01,  1.1313e+00, -7.9871e-01,  3.6817e+00,  2.2286e+00,\n",
       "        -2.2673e+00, -1.8975e+00, -2.6337e+00, -1.0777e+00, -2.0793e+00,\n",
       "        -2.6278e+00, -2.9566e-01,  6.8519e-02, -5.0531e+00, -1.5581e-01,\n",
       "         2.3368e+00, -1.6197e+00,  3.4928e+00, -3.9526e+00, -5.5915e-01,\n",
       "        -1.6986e+00,  9.7405e-01, -2.0541e+00,  1.5466e+00,  2.6860e+00,\n",
       "        -1.1062e+00, -2.2418e-01,  1.6384e+00, -1.3500e+00,  1.3300e+00,\n",
       "        -1.1948e-01,  9.0239e-02,  4.1397e+00, -1.0162e+00,  5.9505e-01,\n",
       "         2.1770e+00, -2.7684e+00,  3.4408e+00, -2.7722e+00,  2.4117e+00,\n",
       "        -7.0685e-01,  1.7667e+00,  7.7749e-01,  2.7677e-01,  8.9423e-01,\n",
       "        -5.2329e-01, -1.1890e+00,  1.0379e+00, -6.3169e-01,  2.0415e+00,\n",
       "         4.0709e+00, -2.9534e+00,  1.4422e+00, -2.5107e+00,  5.3813e-01,\n",
       "        -3.3003e+00,  4.8016e-01, -3.5550e+00,  3.8298e+00,  1.2576e+00,\n",
       "         4.7464e+00,  1.9739e+00, -5.3876e+00, -3.7095e-01, -2.5755e+00,\n",
       "         4.8361e-01,  2.7365e+00,  1.2232e+00,  1.3460e-01,  8.2103e-01,\n",
       "         8.1829e-01, -2.7219e+00,  1.0872e+00,  4.1582e-01, -1.0046e+00,\n",
       "         2.0982e+00, -3.2336e+00,  1.3725e+00, -2.5356e+00,  2.4576e+00,\n",
       "         3.6773e-01, -1.4618e+00,  1.2263e+00,  2.1608e+00, -2.8007e+00,\n",
       "        -4.2904e+00, -3.6653e+00, -1.1368e+00,  6.3629e-01, -3.3690e+00,\n",
       "         2.4244e+00, -3.9946e+00,  2.6268e+00,  1.0718e-01,  9.6677e-01,\n",
       "         3.0943e-01,  1.0159e-01,  6.3940e-01, -4.9451e-01,  8.8268e-01,\n",
       "        -5.6760e-01,  8.9772e-01,  2.1448e+00,  2.8491e+00, -3.3495e+00,\n",
       "        -1.4532e-02,  7.6769e-01, -3.8052e+00, -2.2805e-01,  1.9382e+00,\n",
       "        -2.8943e+00, -3.5722e+00,  3.5580e+00, -9.4311e-01, -2.8680e+00,\n",
       "         2.9117e+00, -8.7352e-01, -5.6923e-01, -2.7640e-01,  1.5750e+00,\n",
       "         4.1278e+00, -7.8470e-01,  2.1290e+00, -7.5151e-01,  3.7485e+00,\n",
       "         7.5662e-02,  3.3410e+00,  2.1089e+00,  1.5189e+00, -1.0976e+00,\n",
       "        -1.5082e+00, -1.3013e+00,  1.0737e+00,  1.3181e+00,  2.4029e+00,\n",
       "         6.3652e-01,  1.8254e+00, -7.5373e-02,  2.9968e+00, -9.2365e-01,\n",
       "         7.0946e-01, -3.1145e+00, -7.1113e+01,  5.2746e-01, -3.5126e-01,\n",
       "         3.8661e-01, -8.2259e+00, -2.6137e+00,  5.0242e+00,  1.5249e-01,\n",
       "         1.2637e-01,  3.3317e-01, -2.2340e+00, -6.6663e-02, -2.0368e+00,\n",
       "        -3.3927e-01, -3.1574e+00, -1.8185e+00,  1.0166e+00,  1.1590e+00,\n",
       "        -1.5948e+00,  2.3276e+00, -2.2635e+00, -1.4386e+00,  2.5087e+00,\n",
       "         2.5586e+00,  1.4100e+00, -1.4065e+00,  2.1102e+00, -1.4391e+00,\n",
       "        -7.0257e-01,  2.1213e+00,  3.4447e+00,  1.3236e+00,  2.9112e+00,\n",
       "        -1.6673e-01,  6.3775e-01, -6.1239e-01, -5.0554e-01,  2.5691e+00,\n",
       "         9.0937e-02,  1.4695e+00,  1.4229e+00, -6.0852e-01,  3.3644e+00,\n",
       "        -4.7408e+00, -2.7515e+00,  7.7352e-03, -1.1554e+00, -3.3896e-01,\n",
       "         1.4231e+00,  5.1408e-02, -1.1397e+00,  2.3839e+00, -1.5253e+00,\n",
       "         1.4644e+00, -2.0470e+00,  8.0636e-01, -1.4410e-01,  4.3553e+00,\n",
       "        -6.1027e-01, -8.9565e-01, -1.2218e+00, -3.2408e+00,  1.0867e+00,\n",
       "         2.5881e+00, -9.1398e-01, -4.2539e+00, -3.5537e+00, -2.5253e+00,\n",
       "         1.7513e+00,  2.8730e+00,  1.7458e+00, -1.0511e+00, -3.4433e-01,\n",
       "        -1.4109e+00, -1.7478e+00,  9.0610e-02,  1.4649e+00, -1.6257e+00,\n",
       "         4.7639e-01,  3.6564e+00, -4.8182e+00,  1.9224e+00,  4.7113e+00,\n",
       "        -3.4745e+00,  1.0501e+00,  1.3614e+00, -2.0103e+00,  3.7251e+00,\n",
       "         1.2678e+00, -5.1648e-01,  7.1394e-01, -1.8459e+00,  3.5218e+00,\n",
       "         7.3257e-01,  2.1970e+00,  1.7494e+00, -3.0829e+00, -2.8488e+00,\n",
       "        -1.8835e+00,  5.1433e-01, -5.1150e-01,  2.5494e+00,  1.2913e+00,\n",
       "         1.4762e+00, -6.7656e-01, -1.1105e+00,  2.2704e+00,  2.7992e+00,\n",
       "        -2.3937e+00, -7.8602e-01,  1.2343e+00, -1.0162e+00, -1.7215e+00,\n",
       "         9.7654e-01,  4.1330e+00, -3.1533e-01,  9.2975e-01, -3.3696e-01,\n",
       "         8.5627e-01,  1.8704e+00,  1.4787e+00,  8.0554e-01,  2.8651e-01,\n",
       "         1.3853e+00, -1.0166e+00, -7.0033e-01, -5.3755e+00, -1.5237e+00,\n",
       "        -2.9511e-01,  1.6396e+00,  4.9963e+00,  2.6047e-01,  4.1415e-01,\n",
       "        -7.9072e-01,  2.2282e+00,  1.4353e+00,  5.1651e-01, -2.5042e+00,\n",
       "         5.7093e-01,  1.4836e+00, -5.0452e+00,  1.5395e+00,  8.6413e-01,\n",
       "         2.0850e+00, -1.9699e+00,  1.2965e-02, -1.2816e+00,  1.1575e+00,\n",
       "        -6.7935e+00,  1.3332e+00, -2.3508e+00, -1.4297e+00, -2.7947e+00,\n",
       "        -1.4830e+00, -2.1206e-01,  2.8099e+00, -9.7490e-01, -2.2466e+00,\n",
       "        -6.9226e-01,  5.0435e-01, -2.0511e+00,  1.0136e+00, -2.8764e-02,\n",
       "        -1.5930e+00,  1.8078e+00,  9.1301e-01,  1.3381e+00, -2.1325e+00,\n",
       "        -1.8719e+00,  7.8008e-01,  8.2017e-01, -1.0173e+00,  1.0689e+00,\n",
       "        -3.3729e+00,  1.4002e+00, -7.8617e-02, -2.6212e+00, -1.1059e+00,\n",
       "        -4.9515e+00,  2.8854e+00,  6.3836e-01,  4.7834e-01, -3.2168e+00,\n",
       "        -5.8729e-02,  3.4430e-01, -4.9071e-01, -2.0117e+00,  2.7876e+00,\n",
       "         2.3717e-01,  2.9994e+00,  1.7922e+00,  1.9067e+00,  1.3172e+00,\n",
       "         7.0966e-01, -1.7569e+00,  3.5796e+00,  1.1373e+00, -3.1848e+00,\n",
       "         1.5771e+00,  1.7646e+00,  3.3648e+00,  2.2048e+00,  3.7952e+00,\n",
       "        -1.7699e+00,  1.0556e+00,  4.6149e-02,  3.1455e+00,  3.6061e+00,\n",
       "        -1.9952e+00,  1.2392e+00,  1.2955e+00])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bank_token = torch.sum(token_embeddings[1][-4:], dim=0) # returns column sum\n",
    "bank_token"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNc+kFZ5lt0XA54aT4VCSas",
   "collapsed_sections": [],
   "name": "Extract_BERT_Embeddings.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit ('con_summary_env': venv)",
   "language": "python",
   "name": "python391jvsc74a57bd012466f790b01845891e8c54f2878097070b87efd364ef8a7c7054cc189b73841"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
